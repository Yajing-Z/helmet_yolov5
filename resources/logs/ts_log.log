2023-07-19T02:38:06,059 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T02:38:06,059 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T02:38:06,145 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T02:38:06,145 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T02:38:06,265 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T02:38:06,265 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T02:38:06,274 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T02:38:06,274 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T02:38:06,296 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T02:38:06,296 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T02:38:06,866 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T02:38:06,866 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T02:38:06,866 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T02:38:06,866 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T02:38:06,866 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T02:38:06,866 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T02:38:06,867 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T02:38:06,867 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T02:38:06,877 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,877 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,879 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,878 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,880 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,879 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,879 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,880 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,879 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,885 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,885 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,886 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,887 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,886 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,887 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,888 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,888 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,887 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,890 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,888 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,887 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,890 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,890 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,890 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,888 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:38:06,894 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T02:38:06,894 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T02:38:07,495 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-07-19T02:38:07,495 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-07-19T02:38:07,495 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T02:38:07,495 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T02:38:07,542 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-07-19T02:38:07,542 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-07-19T02:38:07,543 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T02:38:07,543 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T02:38:07,544 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-07-19T02:38:07,544 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-07-19T02:38:08,358 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T02:38:08,358 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T02:38:08,434 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:08,435 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193443298339844|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:08,436 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.059898376464844|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:08,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:08,437 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:28563.40234375|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:08,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3124.96875|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:08,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:11.1|#Level:Host|#hostname:382211a0865b,timestamp:1689734288
2023-07-19T02:38:09,217 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=1214
2023-07-19T02:38:09,218 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:38:09,230 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,231 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - [PID]1214
2023-07-19T02:38:09,231 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,231 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,231 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,232 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,235 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=1227
2023-07-19T02:38:09,237 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:38:09,237 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:38:09,237 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:38:09,252 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,253 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - [PID]1227
2023-07-19T02:38:09,254 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,254 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,255 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:38:09,255 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:38:09,254 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,263 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2023-07-19T02:38:09,259 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289259
2023-07-19T02:38:09,264 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,259 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289259
2023-07-19T02:38:09,266 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289266
2023-07-19T02:38:09,266 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289266
2023-07-19T02:38:09,266 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2023-07-19T02:38:09,321 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,323 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,401 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=1222
2023-07-19T02:38:09,402 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:38:09,419 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,418 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=1213
2023-07-19T02:38:09,419 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - [PID]1222
2023-07-19T02:38:09,419 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=1229
2023-07-19T02:38:09,420 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,420 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:38:09,420 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,420 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,420 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,421 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:38:09,421 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:38:09,420 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:38:09,423 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289423
2023-07-19T02:38:09,423 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289423
2023-07-19T02:38:09,424 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2023-07-19T02:38:09,434 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,433 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=1209
2023-07-19T02:38:09,434 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - [PID]1229
2023-07-19T02:38:09,434 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:38:09,435 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,435 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,435 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,435 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,435 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,437 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:38:09,437 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:38:09,436 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - [PID]1213
2023-07-19T02:38:09,440 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,440 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,440 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,441 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:38:09,441 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,441 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:38:09,444 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289444
2023-07-19T02:38:09,444 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2023-07-19T02:38:09,444 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289444
2023-07-19T02:38:09,446 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289446
2023-07-19T02:38:09,446 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289446
2023-07-19T02:38:09,446 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2023-07-19T02:38:09,451 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,451 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - [PID]1209
2023-07-19T02:38:09,451 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,452 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,452 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,452 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,452 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:38:09,452 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:38:09,454 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=1225
2023-07-19T02:38:09,454 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:38:09,456 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289456
2023-07-19T02:38:09,456 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2023-07-19T02:38:09,456 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289456
2023-07-19T02:38:09,461 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=1224
2023-07-19T02:38:09,461 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:38:09,465 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,471 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,471 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,472 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - [PID]1225
2023-07-19T02:38:09,472 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,472 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,473 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,473 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,473 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:38:09,473 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:38:09,474 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,476 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2023-07-19T02:38:09,476 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289476
2023-07-19T02:38:09,476 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289476
2023-07-19T02:38:09,477 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,477 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - [PID]1224
2023-07-19T02:38:09,477 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,477 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,478 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,478 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,479 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:38:09,479 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:38:09,480 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=1212
2023-07-19T02:38:09,481 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:38:09,482 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2023-07-19T02:38:09,483 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289483
2023-07-19T02:38:09,483 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289483
2023-07-19T02:38:09,483 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=1230
2023-07-19T02:38:09,484 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:38:09,489 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,490 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,498 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,499 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,499 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - [PID]1230
2023-07-19T02:38:09,500 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,500 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,500 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - [PID]1212
2023-07-19T02:38:09,500 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,500 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,500 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:38:09,500 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:38:09,500 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,500 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,500 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,500 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,501 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:38:09,501 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:38:09,501 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,503 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2023-07-19T02:38:09,503 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,504 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289503
2023-07-19T02:38:09,504 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289503
2023-07-19T02:38:09,505 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289505
2023-07-19T02:38:09,505 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289505
2023-07-19T02:38:09,505 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2023-07-19T02:38:09,525 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=1223
2023-07-19T02:38:09,527 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:38:09,531 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,531 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,537 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,542 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,543 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - [PID]1223
2023-07-19T02:38:09,544 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,544 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,544 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:38:09,544 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:38:09,544 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,545 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,547 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289547
2023-07-19T02:38:09,547 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289547
2023-07-19T02:38:09,551 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2023-07-19T02:38:09,555 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=1232
2023-07-19T02:38:09,555 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:38:09,568 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,569 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - [PID]1232
2023-07-19T02:38:09,569 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,569 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,569 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,569 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,569 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:38:09,569 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:38:09,577 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2023-07-19T02:38:09,578 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,579 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289579
2023-07-19T02:38:09,579 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289579
2023-07-19T02:38:09,601 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=1217
2023-07-19T02:38:09,603 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:38:09,606 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,620 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,629 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - [PID]1217
2023-07-19T02:38:09,629 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,629 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,629 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,629 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,630 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:38:09,630 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:38:09,633 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289633
2023-07-19T02:38:09,633 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2023-07-19T02:38:09,633 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289633
2023-07-19T02:38:09,641 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,650 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,653 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,655 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,658 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,673 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,679 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,680 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=1231
2023-07-19T02:38:09,682 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:38:09,686 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,692 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,693 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,693 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - [PID]1231
2023-07-19T02:38:09,694 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,694 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,694 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,694 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:38:09,694 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:38:09,694 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,697 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289697
2023-07-19T02:38:09,697 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289697
2023-07-19T02:38:09,698 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2023-07-19T02:38:09,719 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,759 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,795 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,799 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=1228
2023-07-19T02:38:09,806 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:38:09,821 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,822 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - [PID]1228
2023-07-19T02:38:09,822 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,822 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,822 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,822 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,823 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:38:09,823 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:38:09,824 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2023-07-19T02:38:09,825 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289825
2023-07-19T02:38:09,825 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289825
2023-07-19T02:38:09,846 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,864 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,865 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:09,880 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:09,880 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:09,880 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-07-19T02:38:09,880 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-07-19T02:38:09,880 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:09,880 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:09,880 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3003.0|#WorkerName:W-9004-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734289
2023-07-19T02:38:09,881 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:80.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734289
2023-07-19T02:38:09,888 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=1226
2023-07-19T02:38:09,889 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:38:09,902 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:38:09,902 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - [PID]1226
2023-07-19T02:38:09,902 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:38:09,903 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:38:09,903 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,903 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:38:09,903 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:38:09,903 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:38:09,906 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289906
2023-07-19T02:38:09,906 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734289906
2023-07-19T02:38:09,906 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2023-07-19T02:38:09,928 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:38:09,988 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:09,988 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:09,988 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 666
2023-07-19T02:38:09,988 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 666
2023-07-19T02:38:09,988 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:09,988 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:09,989 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3111.0|#WorkerName:W-9007-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734289
2023-07-19T02:38:09,989 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:57.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734289
2023-07-19T02:38:10,011 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:10,047 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,047 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,048 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 534
2023-07-19T02:38:10,048 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 534
2023-07-19T02:38:10,049 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,049 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,049 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3172.0|#WorkerName:W-9005-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,050 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:40.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,059 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,059 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,059 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 525
2023-07-19T02:38:10,059 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 525
2023-07-19T02:38:10,059 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,059 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,059 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3183.0|#WorkerName:W-9001-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,060 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:32.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,061 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,061 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,061 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 572
2023-07-19T02:38:10,061 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 572
2023-07-19T02:38:10,062 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,062 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,062 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3188.0|#WorkerName:W-9000-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,062 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:34.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,065 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,065 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,065 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 594
2023-07-19T02:38:10,065 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 594
2023-07-19T02:38:10,066 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,066 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,066 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3190.0|#WorkerName:W-9003-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,066 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,068 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,068 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,068 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 580
2023-07-19T02:38:10,068 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 580
2023-07-19T02:38:10,068 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,068 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,068 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3183.0|#WorkerName:W-9011-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,069 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:45.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,072 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,072 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,072 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 541
2023-07-19T02:38:10,072 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 541
2023-07-19T02:38:10,072 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,072 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,073 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3187.0|#WorkerName:W-9013-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,073 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:27.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,075 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,075 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,075 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 610
2023-07-19T02:38:10,075 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 610
2023-07-19T02:38:10,075 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,075 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,075 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3198.0|#WorkerName:W-9006-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,076 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:43.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,078 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:38:10,083 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,083 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,083 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T02:38:10,083 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T02:38:10,084 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,084 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,084 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3197.0|#WorkerName:W-9014-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,084 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:48.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,161 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,161 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,162 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 555
2023-07-19T02:38:10,162 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 555
2023-07-19T02:38:10,162 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,162 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,163 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3276.0|#WorkerName:W-9012-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,165 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:30.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,204 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,204 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,204 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T02:38:10,204 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T02:38:10,204 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,204 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,205 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3317.0|#WorkerName:W-9015-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,205 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,285 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,285 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,285 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 552
2023-07-19T02:38:10,285 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 552
2023-07-19T02:38:10,285 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,285 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,285 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3407.0|#WorkerName:W-9009-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,286 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:37.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,327 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,327 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,327 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 669
2023-07-19T02:38:10,327 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 669
2023-07-19T02:38:10,327 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,327 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,328 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3452.0|#WorkerName:W-9002-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,328 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,383 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,383 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,383 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 518
2023-07-19T02:38:10,383 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 518
2023-07-19T02:38:10,384 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,384 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,384 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3506.0|#WorkerName:W-9008-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,385 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:41.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,440 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,440 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:10,441 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 512
2023-07-19T02:38:10,441 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 512
2023-07-19T02:38:10,441 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,441 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:38:10,441 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3557.0|#WorkerName:W-9010-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:10,442 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:24.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734290
2023-07-19T02:38:13,044 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734293
2023-07-19T02:38:13,047 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689734293046
2023-07-19T02:38:13,047 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689734293046
2023-07-19T02:38:13,051 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689734293
2023-07-19T02:38:13,101 [WARN ] W-9004-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:38:13,102 [WARN ] W-9004-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:38:13,521 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:469.27|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734293,68959cfa-c788-405f-a738-33a8271927d2, pattern=[METRICS]
2023-07-19T02:38:13,521 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:469.27|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734293,68959cfa-c788-405f-a738-33a8271927d2, pattern=[METRICS]
2023-07-19T02:38:13,521 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:469.27|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:68959cfa-c788-405f-a738-33a8271927d2,timestamp:1689734293
2023-07-19T02:38:13,522 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:469.58|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734293,68959cfa-c788-405f-a738-33a8271927d2, pattern=[METRICS]
2023-07-19T02:38:13,522 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:469.58|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734293,68959cfa-c788-405f-a738-33a8271927d2, pattern=[METRICS]
2023-07-19T02:38:13,522 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:469.58|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:68959cfa-c788-405f-a738-33a8271927d2,timestamp:1689734293
2023-07-19T02:38:13,524 [INFO ] W-9004-helmet_detection_1.0 ACCESS_LOG - /127.0.0.1:54230 "PUT /predictions/helmet_detection HTTP/1.1" 200 482
2023-07-19T02:38:13,525 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734293
2023-07-19T02:38:13,526 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:476717.61|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734293
2023-07-19T02:38:13,526 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:414.925|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734293
2023-07-19T02:38:13,527 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 414925, Backend time ns: 480032713
2023-07-19T02:38:13,527 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 414925, Backend time ns: 480032713
2023-07-19T02:38:13,527 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734293
2023-07-19T02:38:13,527 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:13,527 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:38:13,528 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 474
2023-07-19T02:38:13,528 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 474
2023-07-19T02:38:13,528 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734293
2023-07-19T02:39:08,449 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:39:08,449 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19334411621094|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:39:08,450 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.05999755859375|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:39:08,450 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:39:08,451 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26283.29296875|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:39:08,451 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5405.078125|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:39:08,451 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:382211a0865b,timestamp:1689734348
2023-07-19T02:40:08,435 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:40:08,436 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19334411621094|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:40:08,436 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.05999755859375|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:40:08,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:40:08,437 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26276.93359375|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:40:08,437 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5411.4375|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:40:08,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:382211a0865b,timestamp:1689734408
2023-07-19T02:41:08,432 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:41:08,432 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19334411621094|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:41:08,433 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.05999755859375|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:41:08,433 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:41:08,433 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26282.03125|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:41:08,434 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5406.33984375|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:41:08,434 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:382211a0865b,timestamp:1689734468
2023-07-19T02:42:08,437 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:42:08,438 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:35.19331741333008|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:42:08,439 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:58.06002426147461|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:42:08,439 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:42:08,439 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:26285.69921875|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:42:08,439 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:5402.671875|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:42:08,439 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:382211a0865b,timestamp:1689734528
2023-07-19T02:43:11,869 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T02:43:11,869 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T02:43:11,953 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T02:43:11,953 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T02:43:12,083 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T02:43:12,083 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T02:43:12,096 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T02:43:12,096 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T02:43:12,121 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T02:43:12,121 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T02:43:12,707 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T02:43:12,707 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T02:43:12,708 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T02:43:12,708 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T02:43:12,708 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T02:43:12,708 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T02:43:12,709 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T02:43:12,709 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T02:43:12,720 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,721 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,721 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,721 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,722 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,722 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,722 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,720 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,722 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,721 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,725 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,725 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,725 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,725 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,727 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:43:12,732 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T02:43:12,732 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T02:43:12,948 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T02:43:12,948 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T02:43:12,949 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T02:43:12,949 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T02:43:12,952 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T02:43:12,952 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T02:43:12,953 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T02:43:12,953 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T02:43:12,954 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T02:43:12,954 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T02:43:13,249 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T02:43:13,249 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T02:43:13,314 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:13,315 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19330978393555|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:13,316 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06003189086914|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:13,316 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:13,316 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:29340.04296875|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:13,316 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2348.328125|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:13,317 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:8.6|#Level:Host|#hostname:382211a0865b,timestamp:1689734593
2023-07-19T02:43:15,093 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=1715
2023-07-19T02:43:15,095 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:43:15,107 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,107 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - [PID]1715
2023-07-19T02:43:15,108 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,108 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,108 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,108 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,114 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:43:15,114 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:43:15,133 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2023-07-19T02:43:15,136 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595136
2023-07-19T02:43:15,136 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595136
2023-07-19T02:43:15,158 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=1744
2023-07-19T02:43:15,159 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:43:15,171 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,172 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - [PID]1744
2023-07-19T02:43:15,172 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,172 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,172 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,172 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,173 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:43:15,173 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:43:15,180 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,182 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2023-07-19T02:43:15,182 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595182
2023-07-19T02:43:15,182 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595182
2023-07-19T02:43:15,196 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=1714
2023-07-19T02:43:15,198 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:43:15,198 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=1723
2023-07-19T02:43:15,199 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:43:15,209 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,214 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,215 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - [PID]1714
2023-07-19T02:43:15,215 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,215 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,215 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,215 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,215 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,216 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:43:15,215 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - [PID]1723
2023-07-19T02:43:15,216 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:43:15,216 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,216 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,216 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,216 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,216 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:43:15,216 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:43:15,218 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2023-07-19T02:43:15,219 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595219
2023-07-19T02:43:15,219 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595219
2023-07-19T02:43:15,223 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595223
2023-07-19T02:43:15,223 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595223
2023-07-19T02:43:15,224 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2023-07-19T02:43:15,245 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=1749
2023-07-19T02:43:15,246 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:43:15,251 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,251 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,262 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=1748
2023-07-19T02:43:15,263 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:43:15,268 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,270 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - [PID]1749
2023-07-19T02:43:15,270 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,270 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,270 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,270 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,270 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:43:15,270 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:43:15,272 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595272
2023-07-19T02:43:15,272 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595272
2023-07-19T02:43:15,272 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2023-07-19T02:43:15,278 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,278 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - [PID]1748
2023-07-19T02:43:15,278 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,278 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,279 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,279 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,279 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:43:15,279 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:43:15,280 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=1745
2023-07-19T02:43:15,282 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:43:15,295 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595295
2023-07-19T02:43:15,295 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595295
2023-07-19T02:43:15,295 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2023-07-19T02:43:15,296 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,297 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,298 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - [PID]1745
2023-07-19T02:43:15,298 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,298 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,298 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,298 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,298 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:43:15,298 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:43:15,301 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595301
2023-07-19T02:43:15,301 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595301
2023-07-19T02:43:15,301 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2023-07-19T02:43:15,318 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=1746
2023-07-19T02:43:15,319 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:43:15,321 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=1747
2023-07-19T02:43:15,322 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:43:15,324 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,334 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,335 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - [PID]1746
2023-07-19T02:43:15,335 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,335 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,335 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,335 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:43:15,335 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:43:15,335 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,337 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,338 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595337
2023-07-19T02:43:15,338 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595337
2023-07-19T02:43:15,338 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2023-07-19T02:43:15,335 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=1750
2023-07-19T02:43:15,339 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:43:15,338 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,340 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - [PID]1747
2023-07-19T02:43:15,341 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,341 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,341 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,341 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,341 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:43:15,341 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:43:15,347 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,358 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595358
2023-07-19T02:43:15,358 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595358
2023-07-19T02:43:15,359 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2023-07-19T02:43:15,360 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,360 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - [PID]1750
2023-07-19T02:43:15,360 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,360 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,360 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,360 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,360 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,360 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:43:15,360 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:43:15,363 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595362
2023-07-19T02:43:15,363 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2023-07-19T02:43:15,363 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595362
2023-07-19T02:43:15,368 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,387 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,402 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,401 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=1716
2023-07-19T02:43:15,402 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:43:15,416 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,417 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - [PID]1716
2023-07-19T02:43:15,417 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,417 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,417 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,417 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,418 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:43:15,418 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:43:15,422 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=1712
2023-07-19T02:43:15,423 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:43:15,426 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595426
2023-07-19T02:43:15,426 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2023-07-19T02:43:15,426 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595426
2023-07-19T02:43:15,434 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,437 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,437 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - [PID]1712
2023-07-19T02:43:15,437 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,437 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,437 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,437 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,438 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:43:15,438 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:43:15,439 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2023-07-19T02:43:15,440 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595439
2023-07-19T02:43:15,440 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595439
2023-07-19T02:43:15,450 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,451 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,462 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,463 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,485 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,505 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,507 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,545 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,548 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=1753
2023-07-19T02:43:15,549 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:43:15,557 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,564 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,564 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - [PID]1753
2023-07-19T02:43:15,565 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,565 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,565 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,565 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:43:15,565 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,565 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:43:15,567 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595567
2023-07-19T02:43:15,567 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595567
2023-07-19T02:43:15,567 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2023-07-19T02:43:15,591 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,591 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=1713
2023-07-19T02:43:15,594 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:43:15,608 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,609 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - [PID]1713
2023-07-19T02:43:15,609 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,609 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,609 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,609 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,610 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:43:15,610 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:43:15,611 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,612 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595612
2023-07-19T02:43:15,612 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595612
2023-07-19T02:43:15,613 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2023-07-19T02:43:15,614 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=1751
2023-07-19T02:43:15,614 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:43:15,627 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,629 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,629 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - [PID]1751
2023-07-19T02:43:15,629 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,630 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,630 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,630 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,631 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:43:15,631 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:43:15,633 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2023-07-19T02:43:15,633 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595633
2023-07-19T02:43:15,633 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595633
2023-07-19T02:43:15,642 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,656 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,748 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=1717
2023-07-19T02:43:15,748 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:43:15,752 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,752 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,752 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 543
2023-07-19T02:43:15,752 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 543
2023-07-19T02:43:15,753 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,753 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,753 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3034.0|#WorkerName:W-9005-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,753 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:74.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,761 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:43:15,762 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - [PID]1717
2023-07-19T02:43:15,762 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:43:15,762 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:43:15,762 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,762 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:43:15,763 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:43:15,763 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:43:15,764 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,767 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2023-07-19T02:43:15,769 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595769
2023-07-19T02:43:15,769 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689734595769
2023-07-19T02:43:15,799 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,799 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,799 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 576
2023-07-19T02:43:15,799 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:43:15,799 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 576
2023-07-19T02:43:15,800 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,800 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,800 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3084.0|#WorkerName:W-9000-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,800 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:42.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,806 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,808 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,848 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,848 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,848 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 579
2023-07-19T02:43:15,848 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 579
2023-07-19T02:43:15,848 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,848 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,848 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,848 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,848 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3130.0|#WorkerName:W-9003-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,849 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 535
2023-07-19T02:43:15,849 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 535
2023-07-19T02:43:15,849 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:51.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,849 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,849 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,849 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3131.0|#WorkerName:W-9001-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,849 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:42.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,879 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,879 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,880 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 506
2023-07-19T02:43:15,880 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 506
2023-07-19T02:43:15,880 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,880 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,880 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3155.0|#WorkerName:W-9012-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,881 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:38.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,887 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,887 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,887 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 549
2023-07-19T02:43:15,887 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 549
2023-07-19T02:43:15,887 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,887 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,887 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3161.0|#WorkerName:W-9014-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,887 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:37.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,896 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,896 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,896 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 560
2023-07-19T02:43:15,896 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 560
2023-07-19T02:43:15,896 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,896 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,896 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3171.0|#WorkerName:W-9011-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,897 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:42.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,955 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:43:15,958 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,958 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,959 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 692
2023-07-19T02:43:15,959 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 692
2023-07-19T02:43:15,959 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,959 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,960 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3240.0|#WorkerName:W-9010-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,963 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:48.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,985 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,985 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,986 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 583
2023-07-19T02:43:15,986 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 583
2023-07-19T02:43:15,986 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,986 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,986 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3260.0|#WorkerName:W-9015-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,986 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:45.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,988 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,988 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,988 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 601
2023-07-19T02:43:15,988 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 601
2023-07-19T02:43:15,989 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,989 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,989 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3269.0|#WorkerName:W-9009-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,989 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,997 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,997 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:15,998 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 520
2023-07-19T02:43:15,998 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 520
2023-07-19T02:43:15,998 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,998 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:15,998 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3279.0|#WorkerName:W-9008-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:15,998 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:39.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734595
2023-07-19T02:43:16,003 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,003 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,004 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T02:43:16,004 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T02:43:16,005 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,005 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,007 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3289.0|#WorkerName:W-9002-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,008 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:29.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,144 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,144 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,145 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T02:43:16,145 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T02:43:16,145 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,145 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,147 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3420.0|#WorkerName:W-9013-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,148 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:28.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,171 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,171 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,171 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 501
2023-07-19T02:43:16,171 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 501
2023-07-19T02:43:16,171 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,171 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,172 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3453.0|#WorkerName:W-9007-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,173 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:39.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,175 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,175 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,175 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 534
2023-07-19T02:43:16,175 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 534
2023-07-19T02:43:16,175 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,175 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,176 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3457.0|#WorkerName:W-9004-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,176 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:30.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,330 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,330 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:16,330 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 531
2023-07-19T02:43:16,330 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 531
2023-07-19T02:43:16,330 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,330 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:43:16,330 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3611.0|#WorkerName:W-9006-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:16,331 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:31.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734596
2023-07-19T02:43:19,588 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734599
2023-07-19T02:43:19,591 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689734599591
2023-07-19T02:43:19,591 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689734599591
2023-07-19T02:43:19,593 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689734599
2023-07-19T02:43:19,637 [WARN ] W-9005-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:43:19,638 [WARN ] W-9005-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:43:20,053 [INFO ] W-9005-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:458.97|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734600,06c1a15a-f155-463b-baa3-ea8f7c202834, pattern=[METRICS]
2023-07-19T02:43:20,053 [INFO ] W-9005-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:458.97|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734600,06c1a15a-f155-463b-baa3-ea8f7c202834, pattern=[METRICS]
2023-07-19T02:43:20,053 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:458.97|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:06c1a15a-f155-463b-baa3-ea8f7c202834,timestamp:1689734600
2023-07-19T02:43:20,054 [INFO ] W-9005-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:459.23|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734600,06c1a15a-f155-463b-baa3-ea8f7c202834, pattern=[METRICS]
2023-07-19T02:43:20,054 [INFO ] W-9005-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:459.23|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734600,06c1a15a-f155-463b-baa3-ea8f7c202834, pattern=[METRICS]
2023-07-19T02:43:20,054 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:459.23|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:06c1a15a-f155-463b-baa3-ea8f7c202834,timestamp:1689734600
2023-07-19T02:43:20,055 [INFO ] W-9005-helmet_detection_1.0 ACCESS_LOG - /127.0.0.1:54238 "PUT /predictions/helmet_detection HTTP/1.1" 200 478
2023-07-19T02:43:20,055 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734600
2023-07-19T02:43:20,055 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:463502.484|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734600
2023-07-19T02:43:20,056 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:344.239|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734600
2023-07-19T02:43:20,056 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 344239, Backend time ns: 465058492
2023-07-19T02:43:20,056 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 344239, Backend time ns: 465058492
2023-07-19T02:43:20,057 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734600
2023-07-19T02:43:20,057 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:20,057 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:20,057 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 462
2023-07-19T02:43:20,057 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 462
2023-07-19T02:43:20,057 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734600
2023-07-19T02:43:26,353 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734606
2023-07-19T02:43:26,354 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689734606354
2023-07-19T02:43:26,354 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689734606354
2023-07-19T02:43:26,357 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689734606
2023-07-19T02:43:26,424 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:43:26,425 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:43:26,673 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:315.15|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734606,cf1a7e51-8ce4-4bf6-b8b7-868d2b412a9c, pattern=[METRICS]
2023-07-19T02:43:26,673 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:315.15|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734606,cf1a7e51-8ce4-4bf6-b8b7-868d2b412a9c, pattern=[METRICS]
2023-07-19T02:43:26,673 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:315.15|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:cf1a7e51-8ce4-4bf6-b8b7-868d2b412a9c,timestamp:1689734606
2023-07-19T02:43:26,673 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:315.41|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734606,cf1a7e51-8ce4-4bf6-b8b7-868d2b412a9c, pattern=[METRICS]
2023-07-19T02:43:26,673 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:315.41|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689734606,cf1a7e51-8ce4-4bf6-b8b7-868d2b412a9c, pattern=[METRICS]
2023-07-19T02:43:26,674 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:315.41|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:cf1a7e51-8ce4-4bf6-b8b7-868d2b412a9c,timestamp:1689734606
2023-07-19T02:43:26,674 [INFO ] W-9000-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51044 "POST /predictions/helmet_detection HTTP/1.1" 200 322
2023-07-19T02:43:26,675 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734606
2023-07-19T02:43:26,675 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:319707.042|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734606
2023-07-19T02:43:26,675 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:232.898|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689734606
2023-07-19T02:43:26,675 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 232898, Backend time ns: 321199686
2023-07-19T02:43:26,675 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 232898, Backend time ns: 321199686
2023-07-19T02:43:26,675 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734606
2023-07-19T02:43:26,675 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:26,675 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:43:26,675 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 317
2023-07-19T02:43:26,675 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 317
2023-07-19T02:43:26,676 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734606
2023-07-19T02:44:13,284 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:44:13,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193214416503906|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:44:13,285 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06012725830078|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:44:13,285 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:44:13,286 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26164.03125|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:44:13,286 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5524.33984375|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:44:13,287 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689734653
2023-07-19T02:45:13,284 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:45:13,287 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19321060180664|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:45:13,288 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06013107299805|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:45:13,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:45:13,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26163.73828125|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:45:13,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5524.6328125|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:45:13,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689734713
2023-07-19T02:46:13,283 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:46:13,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19321060180664|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:46:13,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06013107299805|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:46:13,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:46:13,284 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26163.9765625|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:46:13,284 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5524.39453125|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:46:13,285 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689734773
2023-07-19T02:47:13,289 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:47:13,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19321060180664|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:47:13,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06013107299805|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:47:13,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:47:13,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26165.01953125|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:47:13,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5523.3515625|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:47:13,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689734833
2023-07-19T02:48:13,304 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:16.7|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:48:13,305 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193206787109375|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:48:13,308 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06013488769531|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:48:13,310 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:48:13,311 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26163.1171875|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:48:13,313 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5525.25390625|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:48:13,314 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689734893
2023-07-19T02:49:13,291 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:49:13,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193206787109375|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:49:13,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06013488769531|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:49:13,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:49:13,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26163.01171875|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:49:13,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5525.359375|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:49:13,299 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689734953
2023-07-19T02:50:13,307 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:13,308 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193199157714844|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:13,308 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060142517089844|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:13,309 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:13,309 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26163.44921875|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:13,309 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5524.921875|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:13,309 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.5|#Level:Host|#hostname:382211a0865b,timestamp:1689735013
2023-07-19T02:50:56,604 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735056
2023-07-19T02:50:56,605 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735056605
2023-07-19T02:50:56,605 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735056605
2023-07-19T02:50:56,608 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689735056
2023-07-19T02:50:56,629 [WARN ] W-9003-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:50:56,630 [WARN ] W-9003-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:50:56,905 [INFO ] W-9003-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:296.65|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735056,2b7c1d3a-3d3a-4d0e-a1fd-10c6553fcb94, pattern=[METRICS]
2023-07-19T02:50:56,905 [INFO ] W-9003-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:296.65|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735056,2b7c1d3a-3d3a-4d0e-a1fd-10c6553fcb94, pattern=[METRICS]
2023-07-19T02:50:56,906 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:296.65|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:2b7c1d3a-3d3a-4d0e-a1fd-10c6553fcb94,timestamp:1689735056
2023-07-19T02:50:56,906 [INFO ] W-9003-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:297.31|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735056,2b7c1d3a-3d3a-4d0e-a1fd-10c6553fcb94, pattern=[METRICS]
2023-07-19T02:50:56,906 [INFO ] W-9003-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:297.31|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735056,2b7c1d3a-3d3a-4d0e-a1fd-10c6553fcb94, pattern=[METRICS]
2023-07-19T02:50:56,906 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:297.31|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:2b7c1d3a-3d3a-4d0e-a1fd-10c6553fcb94,timestamp:1689735056
2023-07-19T02:50:56,906 [INFO ] W-9003-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51048 "POST /predictions/helmet_detection HTTP/1.1" 200 302
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735056
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:301449.813|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735056
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:282.452|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735056
2023-07-19T02:50:56,907 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 282452, Backend time ns: 301935075
2023-07-19T02:50:56,907 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 282452, Backend time ns: 301935075
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735056
2023-07-19T02:50:56,907 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:50:56,907 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 299
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 299
2023-07-19T02:50:56,907 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735056
2023-07-19T02:51:13,284 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:13,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19317626953125|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:13,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06016540527344|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:13,285 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:13,285 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26054.5390625|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:13,285 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5633.828125|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:13,285 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689735073
2023-07-19T02:51:58,269 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T02:51:58,269 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T02:51:58,357 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T02:51:58,357 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T02:51:58,502 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T02:51:58,502 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T02:51:58,512 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T02:51:58,512 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T02:51:58,538 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T02:51:58,538 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T02:51:59,128 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T02:51:59,128 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T02:51:59,128 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T02:51:59,128 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T02:51:59,128 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T02:51:59,128 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T02:51:59,129 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T02:51:59,129 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T02:51:59,141 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,141 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,142 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,144 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,146 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,147 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T02:51:59,147 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T02:51:59,144 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,147 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,147 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,147 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,147 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,146 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,154 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,154 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T02:51:59,598 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T02:51:59,598 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T02:51:59,611 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T02:51:59,611 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T02:51:59,627 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T02:51:59,627 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T02:51:59,627 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T02:51:59,627 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T02:51:59,628 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T02:51:59,628 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T02:52:00,213 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T02:52:00,213 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T02:52:00,377 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:00,378 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19316864013672|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:00,379 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06017303466797|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:00,379 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:00,379 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:28642.453125|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:00,379 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3045.91796875|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:00,380 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.8|#Level:Host|#hostname:382211a0865b,timestamp:1689735120
2023-07-19T02:52:01,434 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=2276
2023-07-19T02:52:01,435 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:52:01,447 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=2270
2023-07-19T02:52:01,448 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:52:01,452 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,453 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - [PID]2276
2023-07-19T02:52:01,453 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,454 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,454 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,454 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,463 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,464 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - [PID]2270
2023-07-19T02:52:01,465 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:52:01,465 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T02:52:01,465 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,465 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,465 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,467 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:52:01,467 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T02:52:01,467 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,476 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=2281
2023-07-19T02:52:01,477 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:52:01,479 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=2268
2023-07-19T02:52:01,480 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:52:01,480 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2023-07-19T02:52:01,480 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2023-07-19T02:52:01,482 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=2274
2023-07-19T02:52:01,484 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:52:01,486 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121486
2023-07-19T02:52:01,486 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121486
2023-07-19T02:52:01,485 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=2279
2023-07-19T02:52:01,486 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121486
2023-07-19T02:52:01,487 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:52:01,486 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121486
2023-07-19T02:52:01,490 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,491 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - [PID]2281
2023-07-19T02:52:01,491 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,491 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,491 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,491 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,491 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:52:01,491 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T02:52:01,493 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121493
2023-07-19T02:52:01,493 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121493
2023-07-19T02:52:01,493 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2023-07-19T02:52:01,496 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=2283
2023-07-19T02:52:01,501 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:52:01,503 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,503 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - [PID]2279
2023-07-19T02:52:01,504 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,504 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,503 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,504 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,504 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,505 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:52:01,505 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T02:52:01,505 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - [PID]2268
2023-07-19T02:52:01,506 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,506 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,506 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,506 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:52:01,506 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T02:52:01,507 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,507 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2023-07-19T02:52:01,507 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121507
2023-07-19T02:52:01,507 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121507
2023-07-19T02:52:01,510 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121510
2023-07-19T02:52:01,510 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121510
2023-07-19T02:52:01,510 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2023-07-19T02:52:01,511 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,515 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - [PID]2274
2023-07-19T02:52:01,515 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,515 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,515 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,516 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:52:01,516 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T02:52:01,516 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,517 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=2269
2023-07-19T02:52:01,518 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:52:01,518 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2023-07-19T02:52:01,523 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,524 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - [PID]2283
2023-07-19T02:52:01,524 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,524 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,524 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,524 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,525 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:52:01,525 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T02:52:01,549 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121549
2023-07-19T02:52:01,549 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,549 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121549
2023-07-19T02:52:01,550 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - [PID]2269
2023-07-19T02:52:01,550 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,550 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,550 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,550 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,550 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:52:01,550 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T02:52:01,556 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=2266
2023-07-19T02:52:01,557 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:52:01,560 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121560
2023-07-19T02:52:01,560 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121560
2023-07-19T02:52:01,560 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121560
2023-07-19T02:52:01,560 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121560
2023-07-19T02:52:01,561 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2023-07-19T02:52:01,571 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2023-07-19T02:52:01,571 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,571 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - [PID]2266
2023-07-19T02:52:01,572 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,572 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,572 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,572 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,572 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:52:01,572 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T02:52:01,576 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=2275
2023-07-19T02:52:01,577 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:52:01,579 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2023-07-19T02:52:01,580 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121580
2023-07-19T02:52:01,580 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121580
2023-07-19T02:52:01,589 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,590 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - [PID]2275
2023-07-19T02:52:01,590 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,590 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,591 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:52:01,591 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T02:52:01,590 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,604 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,605 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,605 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,606 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,606 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2023-07-19T02:52:01,606 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121606
2023-07-19T02:52:01,606 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121606
2023-07-19T02:52:01,610 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,620 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,621 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,626 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,632 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,620 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,633 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,620 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=2272
2023-07-19T02:52:01,634 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:52:01,635 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=2280
2023-07-19T02:52:01,636 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:52:01,646 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,647 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - [PID]2272
2023-07-19T02:52:01,647 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,647 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,647 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,647 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,648 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:52:01,648 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T02:52:01,650 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,651 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - [PID]2280
2023-07-19T02:52:01,652 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,652 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,651 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,652 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:52:01,652 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T02:52:01,652 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,670 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121670
2023-07-19T02:52:01,670 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121670
2023-07-19T02:52:01,670 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2023-07-19T02:52:01,671 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2023-07-19T02:52:01,671 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121671
2023-07-19T02:52:01,671 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121671
2023-07-19T02:52:01,708 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,711 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,733 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735121
2023-07-19T02:52:01,759 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=2282
2023-07-19T02:52:01,760 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:52:01,780 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,780 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - [PID]2282
2023-07-19T02:52:01,778 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=2273
2023-07-19T02:52:01,780 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,781 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,781 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,781 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,781 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:52:01,781 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T02:52:01,781 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:52:01,783 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121783
2023-07-19T02:52:01,783 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121783
2023-07-19T02:52:01,784 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2023-07-19T02:52:01,796 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,797 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,797 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - [PID]2273
2023-07-19T02:52:01,797 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,798 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,798 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,798 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,798 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:52:01,798 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T02:52:01,803 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,804 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121804
2023-07-19T02:52:01,804 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121804
2023-07-19T02:52:01,804 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,804 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2023-07-19T02:52:01,808 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,809 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,813 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,813 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,820 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,822 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=2278
2023-07-19T02:52:01,823 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:52:01,840 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,847 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,857 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:01,858 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - [PID]2278
2023-07-19T02:52:01,867 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:01,867 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,867 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:01,867 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:01,867 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:52:01,867 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T02:52:01,882 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121882
2023-07-19T02:52:01,882 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735121882
2023-07-19T02:52:01,886 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,895 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2023-07-19T02:52:01,911 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:01,922 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:01,966 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:02,000 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:02,012 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=2277
2023-07-19T02:52:02,013 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:52:02,015 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:02,033 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T02:52:02,033 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - [PID]2277
2023-07-19T02:52:02,033 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T02:52:02,033 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T02:52:02,033 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:02,033 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T02:52:02,034 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:52:02,034 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T02:52:02,037 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2023-07-19T02:52:02,037 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735122037
2023-07-19T02:52:02,037 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689735122037
2023-07-19T02:52:02,061 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:02,066 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T02:52:02,117 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:02,260 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T02:52:02,296 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,296 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,296 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 663
2023-07-19T02:52:02,296 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 663
2023-07-19T02:52:02,297 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,297 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,297 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3155.0|#WorkerName:W-9015-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,298 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:149.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,298 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735122298
2023-07-19T02:52:02,298 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735122298
2023-07-19T02:52:02,300 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689735122
2023-07-19T02:52:02,331 [WARN ] W-9015-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:52:02,332 [WARN ] W-9015-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:52:02,333 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,333 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,333 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 706
2023-07-19T02:52:02,333 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 706
2023-07-19T02:52:02,333 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,333 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,334 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3197.0|#WorkerName:W-9000-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,336 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:70.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,346 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,346 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,346 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 719
2023-07-19T02:52:02,346 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 719
2023-07-19T02:52:02,346 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,346 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,346 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3207.0|#WorkerName:W-9004-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,347 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:48.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,360 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,360 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,360 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 741
2023-07-19T02:52:02,360 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 741
2023-07-19T02:52:02,361 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,361 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,361 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3221.0|#WorkerName:W-9008-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,362 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:61.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,377 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,377 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,378 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732
2023-07-19T02:52:02,378 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732
2023-07-19T02:52:02,378 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,378 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,378 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3238.0|#WorkerName:W-9007-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,379 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:41.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,406 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,406 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,406 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 800
2023-07-19T02:52:02,406 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 800
2023-07-19T02:52:02,406 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,406 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,407 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3268.0|#WorkerName:W-9002-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,407 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:121.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,410 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,410 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,410 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 804
2023-07-19T02:52:02,410 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 804
2023-07-19T02:52:02,410 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,410 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,410 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3269.0|#WorkerName:W-9010-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,410 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:99.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,413 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,413 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,414 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 808
2023-07-19T02:52:02,414 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 808
2023-07-19T02:52:02,414 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,414 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,414 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3274.0|#WorkerName:W-9009-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,415 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:114.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,427 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,427 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,427 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 814
2023-07-19T02:52:02,427 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 814
2023-07-19T02:52:02,427 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,427 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,427 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3289.0|#WorkerName:W-9001-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,428 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:65.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,493 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,493 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,494 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 673
2023-07-19T02:52:02,494 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 673
2023-07-19T02:52:02,494 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,494 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,494 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,494 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,494 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 762
2023-07-19T02:52:02,494 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 762
2023-07-19T02:52:02,494 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,494 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,494 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3353.0|#WorkerName:W-9011-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,494 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:61.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,494 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3355.0|#WorkerName:W-9006-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,495 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:39.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,522 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,522 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,523 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 814
2023-07-19T02:52:02,523 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 814
2023-07-19T02:52:02,523 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,523 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,523 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3382.0|#WorkerName:W-9013-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,523 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:39.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,606 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,606 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,606 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 984
2023-07-19T02:52:02,606 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 984
2023-07-19T02:52:02,606 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,606 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,606 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3467.0|#WorkerName:W-9003-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,607 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:112.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,608 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,608 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,609 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 768
2023-07-19T02:52:02,609 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 768
2023-07-19T02:52:02,609 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,609 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,610 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3468.0|#WorkerName:W-9012-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,610 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:38.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,634 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,634 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,634 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 713
2023-07-19T02:52:02,634 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 713
2023-07-19T02:52:02,645 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,645 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,645 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3506.0|#WorkerName:W-9005-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,646 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:51.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,733 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,733 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,733 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 648
2023-07-19T02:52:02,733 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 648
2023-07-19T02:52:02,733 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,733 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T02:52:02,734 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3592.0|#WorkerName:W-9014-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,735 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:50.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,837 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.35|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735122,523e9f1d-3e0f-4c86-8f03-74026cdffa84, pattern=[METRICS]
2023-07-19T02:52:02,837 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.35|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735122,523e9f1d-3e0f-4c86-8f03-74026cdffa84, pattern=[METRICS]
2023-07-19T02:52:02,838 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:536.35|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:523e9f1d-3e0f-4c86-8f03-74026cdffa84,timestamp:1689735122
2023-07-19T02:52:02,839 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.03|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735122,523e9f1d-3e0f-4c86-8f03-74026cdffa84, pattern=[METRICS]
2023-07-19T02:52:02,839 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.03|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735122,523e9f1d-3e0f-4c86-8f03-74026cdffa84, pattern=[METRICS]
2023-07-19T02:52:02,840 [INFO ] W-9015-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51052 "POST /predictions/helmet_detection HTTP/1.1" 200 1110
2023-07-19T02:52:02,840 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,841 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098147.649|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,841 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:537.03|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:523e9f1d-3e0f-4c86-8f03-74026cdffa84,timestamp:1689735122
2023-07-19T02:52:02,841 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557714.673|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,841 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557714673, Backend time ns: 542941514
2023-07-19T02:52:02,841 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557714673, Backend time ns: 542941514
2023-07-19T02:52:02,841 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:52:02,842 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,842 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:52:02,842 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-07-19T02:52:02,842 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-07-19T02:52:02,842 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735122
2023-07-19T02:53:00,290 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:53:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19307327270508|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:53:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06026840209961|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:53:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:53:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26295.76171875|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:53:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5392.609375|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:53:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:382211a0865b,timestamp:1689735180
2023-07-19T02:54:00,290 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:54:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19306945800781|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:54:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060272216796875|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:54:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:54:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26297.80859375|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:54:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5390.5625|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:54:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:382211a0865b,timestamp:1689735240
2023-07-19T02:55:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19306945800781|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060272216796875|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26293.0390625|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5395.33203125|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:00,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:382211a0865b,timestamp:1689735300
2023-07-19T02:55:10,066 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735310
2023-07-19T02:55:10,067 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735310067
2023-07-19T02:55:10,067 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735310067
2023-07-19T02:55:10,071 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689735310
2023-07-19T02:55:10,088 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:55:10,089 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:55:10,343 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:271.87|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735310,2387041d-8ce5-42fc-aa63-ff9933138f06, pattern=[METRICS]
2023-07-19T02:55:10,343 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:271.87|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735310,2387041d-8ce5-42fc-aa63-ff9933138f06, pattern=[METRICS]
2023-07-19T02:55:10,344 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:271.87|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:2387041d-8ce5-42fc-aa63-ff9933138f06,timestamp:1689735310
2023-07-19T02:55:10,344 [INFO ] W-9000-helmet_detection_1.0 ACCESS_LOG - /10.166.17.44:35732 "POST /predictions/helmet_detection HTTP/1.1" 200 278
2023-07-19T02:55:10,344 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735310
2023-07-19T02:55:10,344 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:272.51|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735310,2387041d-8ce5-42fc-aa63-ff9933138f06, pattern=[METRICS]
2023-07-19T02:55:10,344 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:272.51|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735310,2387041d-8ce5-42fc-aa63-ff9933138f06, pattern=[METRICS]
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:277066.078|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735310
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:322.076|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735310
2023-07-19T02:55:10,345 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 322076, Backend time ns: 277809761
2023-07-19T02:55:10,345 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 322076, Backend time ns: 277809761
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735310
2023-07-19T02:55:10,345 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:272.51|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:2387041d-8ce5-42fc-aa63-ff9933138f06,timestamp:1689735310
2023-07-19T02:55:10,345 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 275
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 275
2023-07-19T02:55:10,345 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735310
2023-07-19T02:55:37,307 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735337
2023-07-19T02:55:37,309 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735337308
2023-07-19T02:55:37,309 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735337308
2023-07-19T02:55:37,312 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689735337
2023-07-19T02:55:37,330 [WARN ] W-9004-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T02:55:37,333 [WARN ] W-9004-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T02:55:37,597 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:284.66|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735337,643fc8ea-83cf-4a2f-9cba-902d0c1ca2f7, pattern=[METRICS]
2023-07-19T02:55:37,597 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:284.66|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735337,643fc8ea-83cf-4a2f-9cba-902d0c1ca2f7, pattern=[METRICS]
2023-07-19T02:55:37,597 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:284.66|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:643fc8ea-83cf-4a2f-9cba-902d0c1ca2f7,timestamp:1689735337
2023-07-19T02:55:37,598 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:285.32|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735337,643fc8ea-83cf-4a2f-9cba-902d0c1ca2f7, pattern=[METRICS]
2023-07-19T02:55:37,598 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:285.32|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689735337,643fc8ea-83cf-4a2f-9cba-902d0c1ca2f7, pattern=[METRICS]
2023-07-19T02:55:37,598 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:285.32|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:643fc8ea-83cf-4a2f-9cba-902d0c1ca2f7,timestamp:1689735337
2023-07-19T02:55:37,598 [INFO ] W-9004-helmet_detection_1.0 ACCESS_LOG - /10.4.139.38:57409 "POST /predictions/helmet_detection HTTP/1.1" 200 292
2023-07-19T02:55:37,598 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735337
2023-07-19T02:55:37,599 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:289825.675|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735337
2023-07-19T02:55:37,599 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:389.343|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735337
2023-07-19T02:55:37,599 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 389343, Backend time ns: 290279370
2023-07-19T02:55:37,599 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 389343, Backend time ns: 290279370
2023-07-19T02:55:37,599 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735337
2023-07-19T02:55:37,599 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:55:37,599 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T02:55:37,599 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 287
2023-07-19T02:55:37,599 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 287
2023-07-19T02:55:37,599 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735337
2023-07-19T02:56:00,288 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:56:00,289 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193058013916016|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:56:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06028366088867|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:56:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:56:00,290 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26114.53125|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:56:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5573.83984375|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:56:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.7|#Level:Host|#hostname:382211a0865b,timestamp:1689735360
2023-07-19T02:57:00,291 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:57:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19305419921875|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:57:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06028747558594|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:57:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:57:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26114.65625|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:57:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5573.71484375|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:57:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.7|#Level:Host|#hostname:382211a0865b,timestamp:1689735420
2023-07-19T02:58:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:58:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19305419921875|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:58:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06028747558594|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:58:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:58:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26111.30859375|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:58:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5577.0625|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:58:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.7|#Level:Host|#hostname:382211a0865b,timestamp:1689735480
2023-07-19T02:59:00,294 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T02:59:00,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19305419921875|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T02:59:00,296 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06028747558594|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T02:59:00,296 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T02:59:00,296 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26110.3828125|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T02:59:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5577.98828125|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T02:59:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.7|#Level:Host|#hostname:382211a0865b,timestamp:1689735540
2023-07-19T03:00:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:00:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19304656982422|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:00:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06029510498047|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:00:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:00:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26110.01953125|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:00:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5578.3515625|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:00:00,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.7|#Level:Host|#hostname:382211a0865b,timestamp:1689735600
2023-07-19T03:01:00,289 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19304656982422|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06029510498047|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26111.24609375|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5577.125|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.7|#Level:Host|#hostname:382211a0865b,timestamp:1689735660
2023-07-19T03:01:22,783 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735682
2023-07-19T03:01:22,783 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735682783
2023-07-19T03:01:22,783 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735682783
2023-07-19T03:01:22,786 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689735682
2023-07-19T03:01:22,787 [WARN ] W-9008-helmet_detection_1.0-stderr MODEL_LOG - /home/model-server/tmp/models/99b8f01d54ea44d0abdeb4d97094fc3e/torchserve_handler.py:52: UserWarning: data params is none
2023-07-19T03:01:22,787 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-07-19T03:01:22,788 [WARN ] W-9008-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn("data params is none")
2023-07-19T03:01:22,788 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-07-19T03:01:22,788 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/service.py", line 134, in predict
2023-07-19T03:01:22,788 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-07-19T03:01:22,788 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 340, in handle
2023-07-19T03:01:22,788 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-07-19T03:01:22,788 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/99b8f01d54ea44d0abdeb4d97094fc3e/torchserve_handler.py", line 53, in preprocess
2023-07-19T03:01:22,789 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG -     raise Exception("no data")
2023-07-19T03:01:22,789 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Exception: no data
2023-07-19T03:01:22,798 [INFO ] W-9008-helmet_detection_1.0 ACCESS_LOG - /10.4.139.38:57804 "POST /predictions/helmet_detection HTTP/1.1" 503 55
2023-07-19T03:01:22,799 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735682
2023-07-19T03:01:22,799 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 204625, Inference time ns: 16294778
2023-07-19T03:01:22,799 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 204625, Inference time ns: 16294778
2023-07-19T03:01:22,800 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:01:22,800 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:01:22,800 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2023-07-19T03:01:22,800 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2023-07-19T03:01:22,800 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:14.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735682
2023-07-19T03:02:00,297 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:02:00,297 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19303512573242|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:02:00,298 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060306549072266|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:02:00,299 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:02:00,300 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26075.703125|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:02:00,301 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5612.66796875|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:02:00,302 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.8|#Level:Host|#hostname:382211a0865b,timestamp:1689735720
2023-07-19T03:03:00,291 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19303512573242|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060306549072266|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26075.33984375|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5613.03125|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.8|#Level:Host|#hostname:382211a0865b,timestamp:1689735780
2023-07-19T03:03:54,224 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689735834
2023-07-19T03:03:54,225 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735834225
2023-07-19T03:03:54,225 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689735834225
2023-07-19T03:03:54,228 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689735834
2023-07-19T03:03:54,230 [WARN ] W-9007-helmet_detection_1.0-stderr MODEL_LOG - /home/model-server/tmp/models/99b8f01d54ea44d0abdeb4d97094fc3e/torchserve_handler.py:52: UserWarning: data params is none
2023-07-19T03:03:54,231 [WARN ] W-9007-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn("data params is none")
2023-07-19T03:03:54,232 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/service.py", line 134, in predict
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 340, in handle
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/99b8f01d54ea44d0abdeb4d97094fc3e/torchserve_handler.py", line 53, in preprocess
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG -     raise Exception("no data")
2023-07-19T03:03:54,233 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Exception: no data
2023-07-19T03:03:54,234 [INFO ] W-9007-helmet_detection_1.0 ACCESS_LOG - /10.4.139.38:57899 "POST /predictions/helmet_detection HTTP/1.1" 503 22
2023-07-19T03:03:54,235 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735834
2023-07-19T03:03:54,235 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 317024, Inference time ns: 10395295
2023-07-19T03:03:54,235 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 317024, Inference time ns: 10395295
2023-07-19T03:03:54,235 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:03:54,235 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:03:54,235 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2023-07-19T03:03:54,235 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2023-07-19T03:03:54,235 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735834
2023-07-19T03:04:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:04:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193031311035156|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:04:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06031036376953|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:04:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:04:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26042.62109375|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:04:00,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5645.75|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:04:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689735840
2023-07-19T03:05:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:05:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19302749633789|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:05:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0603141784668|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:05:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:05:00,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26043.07421875|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:05:00,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5645.296875|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:05:00,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689735900
2023-07-19T03:06:00,289 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:06:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193023681640625|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:06:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06031799316406|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:06:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:06:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26042.72265625|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:06:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5645.6484375|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:06:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689735960
2023-07-19T03:07:00,289 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:07:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193023681640625|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:07:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06031799316406|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:07:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:07:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26041.328125|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:07:00,296 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5647.04296875|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:07:00,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736020
2023-07-19T03:08:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:08:00,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193023681640625|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:08:00,293 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06031799316406|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:08:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:08:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26040.94921875|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:08:00,294 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5647.421875|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:08:00,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736080
2023-07-19T03:09:00,300 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:09:00,302 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19301986694336|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:09:00,310 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06032180786133|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:09:00,310 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:09:00,310 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26041.09375|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:09:00,310 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5647.27734375|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:09:00,311 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736140
2023-07-19T03:10:00,287 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:10:00,288 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193016052246094|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:10:00,288 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060325622558594|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:10:00,289 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:10:00,289 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26040.26953125|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:10:00,289 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5648.1015625|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:10:00,289 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736200
2023-07-19T03:11:00,303 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:11:00,304 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193016052246094|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:11:00,305 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060325622558594|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:11:00,306 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:11:00,306 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26041.09765625|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:11:00,307 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5647.2734375|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:11:00,308 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736260
2023-07-19T03:12:00,294 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:12:00,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.193016052246094|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:12:00,296 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060325622558594|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:12:00,297 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:12:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26040.83984375|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:12:00,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5647.53125|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:12:00,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736320
2023-07-19T03:13:00,288 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:13:00,291 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19301223754883|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:13:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06032943725586|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:13:00,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:13:00,296 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26039.5234375|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:13:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5648.84765625|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:13:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736380
2023-07-19T03:14:00,296 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:14:00,296 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19301223754883|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:14:00,297 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06032943725586|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:14:00,297 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:14:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26039.75390625|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:14:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5648.6171875|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:14:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736440
2023-07-19T03:15:00,283 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:15:00,285 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19300842285156|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:15:00,287 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060333251953125|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:15:00,288 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:15:00,289 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26039.421875|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:15:00,290 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5648.94921875|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:15:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736500
2023-07-19T03:16:00,293 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:16:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19300842285156|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:16:00,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060333251953125|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:16:00,296 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:16:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26039.51171875|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:16:00,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5648.859375|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:16:00,299 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736560
2023-07-19T03:17:00,292 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:17:00,294 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.1930046081543|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:17:00,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06033706665039|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:17:00,296 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:17:00,297 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26041.58203125|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:17:00,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5646.7890625|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:17:00,299 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736620
2023-07-19T03:18:00,287 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:00,288 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.192989349365234|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:00,289 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06035232543945|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:00,290 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:00,291 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26039.390625|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5648.98046875|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:00,292 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.9|#Level:Host|#hostname:382211a0865b,timestamp:1689736680
2023-07-19T03:18:38,333 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T03:18:38,333 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T03:18:38,416 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T03:18:38,416 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T03:18:38,567 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T03:18:38,567 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T03:18:38,576 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T03:18:38,576 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T03:18:38,599 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T03:18:38,599 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T03:18:39,170 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T03:18:39,170 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T03:18:39,170 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T03:18:39,170 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T03:18:39,170 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T03:18:39,170 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T03:18:39,171 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T03:18:39,171 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T03:18:39,183 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,183 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,183 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,185 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,183 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,185 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,186 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,185 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,186 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,185 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,184 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,190 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,192 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,190 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,192 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,193 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:18:39,200 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T03:18:39,200 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T03:18:39,522 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T03:18:39,522 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T03:18:39,523 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T03:18:39,523 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T03:18:39,651 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T03:18:39,651 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T03:18:39,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T03:18:39,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T03:18:39,652 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T03:18:39,652 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T03:18:40,442 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T03:18:40,442 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T03:18:40,599 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:40,601 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19297409057617|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:40,602 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060367584228516|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:40,603 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:40,604 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:28718.92578125|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:40,605 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2969.4453125|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:40,606 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.6|#Level:Host|#hostname:382211a0865b,timestamp:1689736720
2023-07-19T03:18:41,734 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=2849
2023-07-19T03:18:41,735 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:18:41,747 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,748 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - [PID]2849
2023-07-19T03:18:41,748 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,749 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,749 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,749 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,754 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:18:41,754 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:18:41,775 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2023-07-19T03:18:41,779 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721779
2023-07-19T03:18:41,779 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721779
2023-07-19T03:18:41,811 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=2856
2023-07-19T03:18:41,812 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:18:41,827 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:41,839 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,840 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - [PID]2856
2023-07-19T03:18:41,840 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,840 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,841 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,841 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,841 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:18:41,841 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:18:41,855 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721855
2023-07-19T03:18:41,855 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721855
2023-07-19T03:18:41,856 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2023-07-19T03:18:41,870 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=2862
2023-07-19T03:18:41,872 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:18:41,877 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=2859
2023-07-19T03:18:41,878 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:18:41,888 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=2846
2023-07-19T03:18:41,889 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:18:41,890 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:41,892 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,892 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - [PID]2862
2023-07-19T03:18:41,892 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,892 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,892 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,893 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,893 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,893 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - [PID]2859
2023-07-19T03:18:41,893 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:18:41,893 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,893 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:18:41,893 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,894 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,894 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,895 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:18:41,895 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:18:41,899 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721899
2023-07-19T03:18:41,899 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2023-07-19T03:18:41,899 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721899
2023-07-19T03:18:41,902 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721902
2023-07-19T03:18:41,902 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2023-07-19T03:18:41,902 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721902
2023-07-19T03:18:41,910 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,910 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - [PID]2846
2023-07-19T03:18:41,911 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,911 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,911 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,912 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:18:41,912 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:18:41,911 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,918 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721918
2023-07-19T03:18:41,918 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721918
2023-07-19T03:18:41,918 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2023-07-19T03:18:41,933 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:41,939 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:41,956 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:41,955 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=2869
2023-07-19T03:18:41,957 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:18:41,965 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=2863
2023-07-19T03:18:41,966 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:18:41,972 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,972 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - [PID]2869
2023-07-19T03:18:41,973 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,973 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,973 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,973 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:18:41,973 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,973 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:18:41,975 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2023-07-19T03:18:41,976 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721976
2023-07-19T03:18:41,976 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736721976
2023-07-19T03:18:41,985 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=2866
2023-07-19T03:18:41,986 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:18:41,978 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=2850
2023-07-19T03:18:41,987 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:18:41,997 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:41,999 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:41,999 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - [PID]2850
2023-07-19T03:18:41,999 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=2864
2023-07-19T03:18:41,999 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:41,999 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:18:41,999 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:41,999 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:41,999 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,000 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:18:42,000 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:18:42,005 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,006 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - [PID]2866
2023-07-19T03:18:42,006 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,007 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,010 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,010 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,010 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:18:42,010 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:18:42,011 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,011 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - [PID]2863
2023-07-19T03:18:42,012 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,012 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722012
2023-07-19T03:18:42,011 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,012 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722012
2023-07-19T03:18:42,012 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,012 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,013 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:18:42,013 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:18:42,013 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722013
2023-07-19T03:18:42,013 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722013
2023-07-19T03:18:42,014 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,014 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2023-07-19T03:18:42,021 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,021 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2023-07-19T03:18:42,021 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - [PID]2864
2023-07-19T03:18:42,025 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722025
2023-07-19T03:18:42,025 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722025
2023-07-19T03:18:42,025 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,026 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,026 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,025 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2023-07-19T03:18:42,026 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,026 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:18:42,026 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:18:42,054 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2023-07-19T03:18:42,066 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,069 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722069
2023-07-19T03:18:42,069 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722069
2023-07-19T03:18:42,073 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,075 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=2860
2023-07-19T03:18:42,075 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:18:42,076 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,089 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,089 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - [PID]2860
2023-07-19T03:18:42,089 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,089 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,090 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,090 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,090 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:18:42,090 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:18:42,092 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722092
2023-07-19T03:18:42,092 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722092
2023-07-19T03:18:42,092 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2023-07-19T03:18:42,102 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,106 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,118 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,129 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,137 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=2868
2023-07-19T03:18:42,137 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=2867
2023-07-19T03:18:42,138 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:18:42,138 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:18:42,144 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,152 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,152 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - [PID]2867
2023-07-19T03:18:42,152 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,153 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,152 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,152 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,154 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:18:42,154 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - [PID]2868
2023-07-19T03:18:42,154 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,154 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,154 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,154 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,154 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,154 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:18:42,154 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:18:42,154 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:18:42,156 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2023-07-19T03:18:42,156 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722156
2023-07-19T03:18:42,156 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722156
2023-07-19T03:18:42,162 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722162
2023-07-19T03:18:42,162 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2023-07-19T03:18:42,162 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722162
2023-07-19T03:18:42,182 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,185 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,188 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=2861
2023-07-19T03:18:42,189 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:18:42,190 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,197 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,205 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,205 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - [PID]2861
2023-07-19T03:18:42,205 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,206 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,206 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,206 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:18:42,206 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:18:42,206 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,208 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2023-07-19T03:18:42,208 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722208
2023-07-19T03:18:42,208 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722208
2023-07-19T03:18:42,235 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=2865
2023-07-19T03:18:42,235 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=2852
2023-07-19T03:18:42,236 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:18:42,237 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,236 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:18:42,242 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,249 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,250 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - [PID]2865
2023-07-19T03:18:42,250 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,250 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,250 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,250 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,250 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:18:42,250 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:18:42,252 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722252
2023-07-19T03:18:42,252 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722252
2023-07-19T03:18:42,253 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:18:42,253 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - [PID]2852
2023-07-19T03:18:42,254 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:18:42,254 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,254 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:18:42,254 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2023-07-19T03:18:42,254 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:18:42,255 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:18:42,255 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:18:42,257 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2023-07-19T03:18:42,258 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722258
2023-07-19T03:18:42,258 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736722258
2023-07-19T03:18:42,262 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,268 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,280 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,282 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,283 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,302 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:18:42,345 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,373 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,397 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,413 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,413 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,413 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 572
2023-07-19T03:18:42,413 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 572
2023-07-19T03:18:42,414 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,414 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,414 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3235.0|#WorkerName:W-9000-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,414 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:63.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,484 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,502 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,502 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,502 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 611
2023-07-19T03:18:42,502 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 611
2023-07-19T03:18:42,503 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,503 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,503 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3322.0|#WorkerName:W-9003-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,504 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:38.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,507 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:18:42,555 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,555 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,555 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 616
2023-07-19T03:18:42,555 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 616
2023-07-19T03:18:42,557 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,557 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,557 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3376.0|#WorkerName:W-9002-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,558 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:40.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,566 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,566 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,566 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 595
2023-07-19T03:18:42,566 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 595
2023-07-19T03:18:42,567 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,567 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,567 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3386.0|#WorkerName:W-9005-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,568 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:55.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,636 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,636 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,636 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 704
2023-07-19T03:18:42,636 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 704
2023-07-19T03:18:42,637 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,637 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,637 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3454.0|#WorkerName:W-9010-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,638 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:34.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,678 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,678 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,678 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 560
2023-07-19T03:18:42,678 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 560
2023-07-19T03:18:42,678 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,678 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,678 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,678 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,679 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 610
2023-07-19T03:18:42,679 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 610
2023-07-19T03:18:42,679 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,679 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,679 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3485.0|#WorkerName:W-9015-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,679 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:94.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,679 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3499.0|#WorkerName:W-9001-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,679 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:57.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,694 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,694 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,695 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 619
2023-07-19T03:18:42,695 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 619
2023-07-19T03:18:42,695 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,695 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,695 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3505.0|#WorkerName:W-9014-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,695 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:63.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,698 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,698 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,698 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 580
2023-07-19T03:18:42,698 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 580
2023-07-19T03:18:42,698 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,698 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,699 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3516.0|#WorkerName:W-9009-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,699 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:27.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,701 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,701 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,701 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,701 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 584
2023-07-19T03:18:42,701 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 584
2023-07-19T03:18:42,701 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,701 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,701 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,701 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3519.0|#WorkerName:W-9007-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,702 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:49.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,702 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 684
2023-07-19T03:18:42,702 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 684
2023-07-19T03:18:42,702 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,702 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,703 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3516.0|#WorkerName:W-9011-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,703 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:43.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,748 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,748 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,749 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T03:18:42,749 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 553
2023-07-19T03:18:42,749 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,749 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,749 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3563.0|#WorkerName:W-9012-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,750 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:35.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,794 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,794 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,795 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 558
2023-07-19T03:18:42,795 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 558
2023-07-19T03:18:42,795 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,795 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,795 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3614.0|#WorkerName:W-9004-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,796 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:30.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,833 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,833 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,833 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T03:18:42,833 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T03:18:42,834 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,834 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,834 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3645.0|#WorkerName:W-9013-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,835 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:46.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,880 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,880 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:42,880 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 599
2023-07-19T03:18:42,880 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 599
2023-07-19T03:18:42,880 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,880 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:42,881 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3698.0|#WorkerName:W-9008-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:42,881 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:30.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736722
2023-07-19T03:18:43,053 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:43,053 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:43,054 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 750
2023-07-19T03:18:43,054 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 750
2023-07-19T03:18:43,054 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:43,054 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:18:43,054 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3872.0|#WorkerName:W-9006-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736723
2023-07-19T03:18:43,056 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:47.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736723
2023-07-19T03:18:44,490 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736724
2023-07-19T03:18:44,492 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689736724492
2023-07-19T03:18:44,492 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689736724492
2023-07-19T03:18:44,496 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689736724
2023-07-19T03:18:44,516 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T03:18:44,517 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T03:18:44,842 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:345.42|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736724,ec575177-8e6c-4e8b-86c4-66daa100e1cd, pattern=[METRICS]
2023-07-19T03:18:44,842 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:345.42|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736724,ec575177-8e6c-4e8b-86c4-66daa100e1cd, pattern=[METRICS]
2023-07-19T03:18:44,843 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:345.42|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:ec575177-8e6c-4e8b-86c4-66daa100e1cd,timestamp:1689736724
2023-07-19T03:18:44,843 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:346.24|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736724,ec575177-8e6c-4e8b-86c4-66daa100e1cd, pattern=[METRICS]
2023-07-19T03:18:44,843 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:346.24|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736724,ec575177-8e6c-4e8b-86c4-66daa100e1cd, pattern=[METRICS]
2023-07-19T03:18:44,843 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:346.24|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:ec575177-8e6c-4e8b-86c4-66daa100e1cd,timestamp:1689736724
2023-07-19T03:18:44,845 [INFO ] W-9000-helmet_detection_1.0 ACCESS_LOG - /10.166.17.40:42826 "POST /predictions/helmet_detection HTTP/1.1" 200 358
2023-07-19T03:18:44,846 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736724
2023-07-19T03:18:44,846 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:352577.402|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736724
2023-07-19T03:18:44,846 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:423.979|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736724
2023-07-19T03:18:44,847 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 423979, Backend time ns: 354384007
2023-07-19T03:18:44,847 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 423979, Backend time ns: 354384007
2023-07-19T03:18:44,847 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736724
2023-07-19T03:18:44,847 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:44,847 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:18:44,847 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 349
2023-07-19T03:18:44,847 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 349
2023-07-19T03:18:44,847 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:6.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736724
2023-07-19T03:19:32,073 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T03:19:32,073 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T03:19:32,154 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T03:19:32,154 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T03:19:32,283 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T03:19:32,283 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T03:19:32,307 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T03:19:32,307 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T03:19:32,333 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T03:19:32,333 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T03:19:32,926 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T03:19:32,926 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T03:19:32,927 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T03:19:32,927 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T03:19:32,927 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T03:19:32,927 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T03:19:32,927 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T03:19:32,927 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T03:19:32,937 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,937 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,938 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,939 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,938 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,938 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,941 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,939 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,942 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,941 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,943 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,942 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,938 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,943 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,943 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,943 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,944 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,944 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,948 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,947 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,948 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,949 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,947 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,939 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,949 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,949 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,939 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,949 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,950 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,950 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,950 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,950 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:19:32,953 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T03:19:32,953 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T03:19:33,284 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T03:19:33,284 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T03:19:33,285 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T03:19:33,285 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T03:19:33,302 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T03:19:33,302 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T03:19:33,302 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T03:19:33,302 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T03:19:33,303 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T03:19:33,303 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T03:19:33,998 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T03:19:33,998 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T03:19:34,249 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:85.7|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:34,250 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.192867279052734|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:34,251 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06047439575195|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:34,251 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:34,252 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:28748.296875|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:34,252 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2940.07421875|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:34,253 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.5|#Level:Host|#hostname:382211a0865b,timestamp:1689736774
2023-07-19T03:19:35,398 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=3360
2023-07-19T03:19:35,400 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:19:35,418 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,419 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - [PID]3360
2023-07-19T03:19:35,420 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,420 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,420 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,421 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,427 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:19:35,427 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:19:35,449 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2023-07-19T03:19:35,453 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775452
2023-07-19T03:19:35,453 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775452
2023-07-19T03:19:35,462 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=3352
2023-07-19T03:19:35,464 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:19:35,479 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,480 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - [PID]3352
2023-07-19T03:19:35,481 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,481 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,481 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,482 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:19:35,482 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:19:35,482 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,484 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775483
2023-07-19T03:19:35,484 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775483
2023-07-19T03:19:35,484 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2023-07-19T03:19:35,511 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=3390
2023-07-19T03:19:35,513 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:19:35,519 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,521 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - [PID]3390
2023-07-19T03:19:35,520 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=3388
2023-07-19T03:19:35,521 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,521 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,521 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,521 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,522 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:19:35,522 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:19:35,522 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:19:35,523 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,524 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,525 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2023-07-19T03:19:35,525 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775525
2023-07-19T03:19:35,525 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775525
2023-07-19T03:19:35,537 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,538 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - [PID]3388
2023-07-19T03:19:35,538 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,539 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,539 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,539 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:19:35,539 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:19:35,539 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,552 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=3387
2023-07-19T03:19:35,552 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:19:35,553 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2023-07-19T03:19:35,553 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,554 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775554
2023-07-19T03:19:35,554 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775554
2023-07-19T03:19:35,573 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=3385
2023-07-19T03:19:35,571 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=3358
2023-07-19T03:19:35,584 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:19:35,584 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,586 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - [PID]3387
2023-07-19T03:19:35,586 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,587 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,587 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,587 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,587 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:19:35,587 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:19:35,585 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:19:35,589 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,590 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2023-07-19T03:19:35,590 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - [PID]3385
2023-07-19T03:19:35,591 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,591 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,591 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,591 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,591 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:19:35,591 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:19:35,591 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775591
2023-07-19T03:19:35,591 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775591
2023-07-19T03:19:35,592 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,593 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - [PID]3358
2023-07-19T03:19:35,593 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,593 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,593 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,593 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,593 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,593 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2023-07-19T03:19:35,594 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:19:35,594 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:19:35,594 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775594
2023-07-19T03:19:35,594 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775594
2023-07-19T03:19:35,595 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775595
2023-07-19T03:19:35,595 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775595
2023-07-19T03:19:35,596 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2023-07-19T03:19:35,616 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,620 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,629 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=3383
2023-07-19T03:19:35,630 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:19:35,634 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,634 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=3350
2023-07-19T03:19:35,635 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:19:35,637 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=3349
2023-07-19T03:19:35,638 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:19:35,645 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,645 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - [PID]3383
2023-07-19T03:19:35,646 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,646 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,646 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,646 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,647 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:19:35,647 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:19:35,652 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,653 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - [PID]3349
2023-07-19T03:19:35,654 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,654 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2023-07-19T03:19:35,654 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,654 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,654 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,654 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775654
2023-07-19T03:19:35,654 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775654
2023-07-19T03:19:35,654 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:19:35,654 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:19:35,657 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775657
2023-07-19T03:19:35,657 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775657
2023-07-19T03:19:35,662 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,663 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - [PID]3350
2023-07-19T03:19:35,663 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,663 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,663 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,663 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,663 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:19:35,663 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:19:35,665 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2023-07-19T03:19:35,666 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2023-07-19T03:19:35,665 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=3359
2023-07-19T03:19:35,667 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:19:35,669 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775669
2023-07-19T03:19:35,669 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775669
2023-07-19T03:19:35,681 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,682 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,682 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - [PID]3359
2023-07-19T03:19:35,683 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,683 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,686 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,689 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,689 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,689 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:19:35,689 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:19:35,693 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775693
2023-07-19T03:19:35,693 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775693
2023-07-19T03:19:35,694 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2023-07-19T03:19:35,694 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=3384
2023-07-19T03:19:35,694 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:19:35,697 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,710 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,710 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - [PID]3384
2023-07-19T03:19:35,710 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,710 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,711 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,711 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,711 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:19:35,711 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:19:35,712 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775712
2023-07-19T03:19:35,712 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775712
2023-07-19T03:19:35,717 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,717 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,721 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2023-07-19T03:19:35,733 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,752 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,767 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,767 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,779 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,785 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=3386
2023-07-19T03:19:35,786 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:19:35,802 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,802 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - [PID]3386
2023-07-19T03:19:35,802 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,802 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,803 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,803 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,803 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:19:35,803 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:19:35,807 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775806
2023-07-19T03:19:35,806 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2023-07-19T03:19:35,807 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775806
2023-07-19T03:19:35,833 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,836 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,851 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=3345
2023-07-19T03:19:35,852 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:19:35,859 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=3391
2023-07-19T03:19:35,860 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:19:35,867 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,867 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,868 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - [PID]3345
2023-07-19T03:19:35,868 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,869 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,869 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,870 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,870 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:19:35,870 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:19:35,872 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2023-07-19T03:19:35,872 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775872
2023-07-19T03:19:35,872 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775872
2023-07-19T03:19:35,876 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,876 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - [PID]3391
2023-07-19T03:19:35,876 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,876 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,876 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,876 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,877 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:19:35,877 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:19:35,878 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2023-07-19T03:19:35,879 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775879
2023-07-19T03:19:35,879 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775879
2023-07-19T03:19:35,882 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,882 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,885 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,893 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,894 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,901 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:35,906 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=3389
2023-07-19T03:19:35,907 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:19:35,922 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:19:35,922 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - [PID]3389
2023-07-19T03:19:35,922 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:19:35,922 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:19:35,924 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,924 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:19:35,924 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:19:35,924 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:19:35,927 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2023-07-19T03:19:35,934 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775934
2023-07-19T03:19:35,934 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689736775934
2023-07-19T03:19:35,946 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:35,957 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:19:36,053 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:36,070 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:36,087 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:36,130 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:19:36,199 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,199 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,199 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 675
2023-07-19T03:19:36,199 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 675
2023-07-19T03:19:36,200 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,200 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,201 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3263.0|#WorkerName:W-9004-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,201 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:43.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,212 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,212 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,212 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 688
2023-07-19T03:19:36,212 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 688
2023-07-19T03:19:36,212 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,212 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,212 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3265.0|#WorkerName:W-9015-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,213 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:73.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,218 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,218 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,218 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 585
2023-07-19T03:19:36,218 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 585
2023-07-19T03:19:36,218 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,218 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,218 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3280.0|#WorkerName:W-9007-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,219 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:40.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,246 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,246 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,246 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 637
2023-07-19T03:19:36,246 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 637
2023-07-19T03:19:36,246 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,246 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,247 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3304.0|#WorkerName:W-9009-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,248 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:57.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,257 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,257 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,257 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 705
2023-07-19T03:19:36,257 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 705
2023-07-19T03:19:36,257 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,257 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,258 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3313.0|#WorkerName:W-9011-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,258 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:28.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,305 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,305 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,305 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,305 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,305 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 584
2023-07-19T03:19:36,305 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 584
2023-07-19T03:19:36,305 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,305 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,305 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 689
2023-07-19T03:19:36,305 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 689
2023-07-19T03:19:36,305 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,305 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3367.0|#WorkerName:W-9006-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,305 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,306 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:29.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,306 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3364.0|#WorkerName:W-9010-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,306 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,319 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,319 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,320 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 633
2023-07-19T03:19:36,320 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 633
2023-07-19T03:19:36,320 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,320 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,320 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3385.0|#WorkerName:W-9000-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,320 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:30.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,353 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,353 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,354 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 643
2023-07-19T03:19:36,354 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 643
2023-07-19T03:19:36,354 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,354 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,354 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,354 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,354 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 661
2023-07-19T03:19:36,354 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 661
2023-07-19T03:19:36,354 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,354 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,355 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3407.0|#WorkerName:W-9014-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,355 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3417.0|#WorkerName:W-9003-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,357 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:40.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,357 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:45.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,377 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,377 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,378 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 645
2023-07-19T03:19:36,378 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 645
2023-07-19T03:19:36,378 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,378 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,379 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3433.0|#WorkerName:W-9012-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,380 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:22.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,417 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,417 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,418 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 783
2023-07-19T03:19:36,418 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 783
2023-07-19T03:19:36,418 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,418 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,419 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3479.0|#WorkerName:W-9008-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,420 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:41.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,464 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,464 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,464 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 555
2023-07-19T03:19:36,464 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 555
2023-07-19T03:19:36,464 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,464 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,464 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3528.0|#WorkerName:W-9001-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,465 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:37.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,487 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,487 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,487 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 564
2023-07-19T03:19:36,487 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 564
2023-07-19T03:19:36,487 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,487 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,487 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3551.0|#WorkerName:W-9002-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,488 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:45.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,525 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,525 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,525 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 692
2023-07-19T03:19:36,525 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 692
2023-07-19T03:19:36,526 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,526 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,527 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3588.0|#WorkerName:W-9005-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,527 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:29.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,533 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,533 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:36,534 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 576
2023-07-19T03:19:36,534 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 576
2023-07-19T03:19:36,534 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,534 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:19:36,535 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3588.0|#WorkerName:W-9013-helmet_detection_1.0,Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:36,536 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736776
2023-07-19T03:19:37,638 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736777
2023-07-19T03:19:37,641 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689736777641
2023-07-19T03:19:37,641 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689736777641
2023-07-19T03:19:37,643 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689736777
2023-07-19T03:19:37,659 [WARN ] W-9004-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T03:19:37,659 [WARN ] W-9004-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T03:19:37,932 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:288.26|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736777,21b67bc5-462b-44eb-9975-b49e6ef65058, pattern=[METRICS]
2023-07-19T03:19:37,932 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:288.26|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736777,21b67bc5-462b-44eb-9975-b49e6ef65058, pattern=[METRICS]
2023-07-19T03:19:37,933 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:288.26|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:21b67bc5-462b-44eb-9975-b49e6ef65058,timestamp:1689736777
2023-07-19T03:19:37,933 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:288.96|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736777,21b67bc5-462b-44eb-9975-b49e6ef65058, pattern=[METRICS]
2023-07-19T03:19:37,933 [INFO ] W-9004-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:288.96|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,1689736777,21b67bc5-462b-44eb-9975-b49e6ef65058, pattern=[METRICS]
2023-07-19T03:19:37,933 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:288.96|#ModelName:helmet_detection,Level:Model|#hostname:382211a0865b,requestID:21b67bc5-462b-44eb-9975-b49e6ef65058,timestamp:1689736777
2023-07-19T03:19:37,935 [INFO ] W-9004-helmet_detection_1.0 ACCESS_LOG - /10.166.17.40:43026 "POST /predictions/helmet_detection HTTP/1.1" 200 308
2023-07-19T03:19:37,936 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736777
2023-07-19T03:19:37,936 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:293707.978|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736777
2023-07-19T03:19:37,936 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:415.25|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736777
2023-07-19T03:19:37,937 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 415250, Backend time ns: 295442083
2023-07-19T03:19:37,937 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 415250, Backend time ns: 295442083
2023-07-19T03:19:37,937 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736777
2023-07-19T03:19:37,937 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:37,937 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:19:37,937 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 292
2023-07-19T03:19:37,937 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 292
2023-07-19T03:19:37,937 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736777
2023-07-19T03:20:34,047 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:20:34,048 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.19278335571289|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:20:34,048 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0605583190918|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:20:34,048 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:20:34,049 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26280.74609375|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:20:34,049 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5407.625|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:20:34,049 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:382211a0865b,timestamp:1689736834
2023-07-19T03:21:34,042 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:34,042 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.192779541015625|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:34,043 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06056213378906|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:34,043 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:34,043 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26280.26171875|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:34,043 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5408.109375|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:34,044 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:382211a0865b,timestamp:1689736894
2023-07-19T03:21:51,751 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:382211a0865b,timestamp:1689736911
2023-07-19T03:21:51,752 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689736911752
2023-07-19T03:21:51,752 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689736911752
2023-07-19T03:21:51,756 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689736911
2023-07-19T03:21:51,759 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-07-19T03:21:51,759 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-07-19T03:21:51,759 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/service.py", line 134, in predict
2023-07-19T03:21:51,760 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-07-19T03:21:51,760 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 340, in handle
2023-07-19T03:21:51,758 [WARN ] W-9015-helmet_detection_1.0-stderr MODEL_LOG - /home/model-server/tmp/models/87ae745e279546a7963c7dd9c29f691a/torchserve_handler.py:52: UserWarning: data params is none
2023-07-19T03:21:51,760 [WARN ] W-9015-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn("data params is none")
2023-07-19T03:21:51,760 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-07-19T03:21:51,760 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/87ae745e279546a7963c7dd9c29f691a/torchserve_handler.py", line 53, in preprocess
2023-07-19T03:21:51,760 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG -     raise Exception("no data")
2023-07-19T03:21:51,760 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Exception: no data
2023-07-19T03:21:51,767 [INFO ] W-9015-helmet_detection_1.0 ACCESS_LOG - /10.4.139.38:58743 "POST /predictions/helmet_detection HTTP/1.1" 503 43
2023-07-19T03:21:51,768 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736911
2023-07-19T03:21:51,768 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 332601, Inference time ns: 16653342
2023-07-19T03:21:51,768 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 332601, Inference time ns: 16653342
2023-07-19T03:21:51,768 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:21:51,768 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:21:51,768 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2023-07-19T03:21:51,768 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2023-07-19T03:21:51,769 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:12.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736911
2023-07-19T03:22:34,044 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:22:34,044 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.192771911621094|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:22:34,045 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.060569763183594|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:22:34,045 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:22:34,045 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26248.62109375|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:22:34,045 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5439.75|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:22:34,045 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.3|#Level:Host|#hostname:382211a0865b,timestamp:1689736954
2023-07-19T03:34:07,937 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T03:34:07,937 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-07-19T03:34:08,037 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T03:34:08,037 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-07-19T03:34:08,192 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T03:34:08,192 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.1
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /mnt
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8032 M
Python executable: /home/venv/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/model_store
Initial Models: ./model_store/helmet_detection.mar
Log dir: /mnt/logs
Metrics dir: /mnt/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 655350000
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/model_store
Model config: N/A
2023-07-19T03:34:08,203 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T03:34:08,203 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-07-19T03:34:08,227 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T03:34:08,227 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: ./model_store/helmet_detection.mar
2023-07-19T03:34:08,803 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T03:34:08,803 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model helmet_detection
2023-07-19T03:34:08,804 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T03:34:08,804 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model helmet_detection
2023-07-19T03:34:08,804 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T03:34:08,804 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-07-19T03:34:08,805 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T03:34:08,805 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-07-19T03:34:08,817 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9004, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,817 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9001, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,820 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,819 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9003, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,820 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9010, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,819 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9009, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9002, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9007, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,823 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,822 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,823 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9011, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,822 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9008, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,824 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,824 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,825 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,824 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9013, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,825 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,824 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9012, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,825 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9015, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,825 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9014, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9005, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,818 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9006, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-07-19T03:34:08,828 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T03:34:08,828 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-07-19T03:34:09,213 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T03:34:09,213 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-07-19T03:34:09,214 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T03:34:09,214 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-07-19T03:34:09,422 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T03:34:09,422 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-07-19T03:34:09,422 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T03:34:09,422 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-07-19T03:34:09,423 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T03:34:09,423 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-07-19T03:34:10,070 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T03:34:10,070 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-07-19T03:34:10,218 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:10,219 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.1844367980957|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:10,220 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.068904876708984|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:10,220 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:10,220 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:28720.4609375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:10,221 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2967.34765625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:10,221 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737650
2023-07-19T03:34:11,326 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=97
2023-07-19T03:34:11,328 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:34:11,343 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,343 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - [PID]97
2023-07-19T03:34:11,344 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,344 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,344 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,344 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,351 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:34:11,351 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2023-07-19T03:34:11,366 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2023-07-19T03:34:11,370 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651370
2023-07-19T03:34:11,370 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651370
2023-07-19T03:34:11,387 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=109
2023-07-19T03:34:11,389 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:34:11,394 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=106
2023-07-19T03:34:11,395 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:34:11,406 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,406 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - [PID]109
2023-07-19T03:34:11,407 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,407 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,407 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,407 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,407 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:34:11,407 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2023-07-19T03:34:11,409 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2023-07-19T03:34:11,410 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651409
2023-07-19T03:34:11,410 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651409
2023-07-19T03:34:11,412 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,413 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - [PID]106
2023-07-19T03:34:11,413 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,413 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,413 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,413 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,414 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:34:11,414 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2023-07-19T03:34:11,416 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2023-07-19T03:34:11,416 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651416
2023-07-19T03:34:11,416 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651416
2023-07-19T03:34:11,433 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=92
2023-07-19T03:34:11,434 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:34:11,449 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=105
2023-07-19T03:34:11,449 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:34:11,455 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,456 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - [PID]92
2023-07-19T03:34:11,456 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,456 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,457 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,456 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,457 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:34:11,457 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2023-07-19T03:34:11,459 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,459 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651459
2023-07-19T03:34:11,459 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651459
2023-07-19T03:34:11,460 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,461 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2023-07-19T03:34:11,465 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,466 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - [PID]105
2023-07-19T03:34:11,466 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,466 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,466 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,466 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,466 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:34:11,466 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2023-07-19T03:34:11,473 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,493 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=93
2023-07-19T03:34:11,496 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:34:11,498 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651498
2023-07-19T03:34:11,498 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651498
2023-07-19T03:34:11,499 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2023-07-19T03:34:11,508 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,509 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - [PID]93
2023-07-19T03:34:11,511 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,511 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,511 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:34:11,511 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2023-07-19T03:34:11,510 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,512 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,513 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2023-07-19T03:34:11,518 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651518
2023-07-19T03:34:11,518 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651518
2023-07-19T03:34:11,521 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,524 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,525 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=95
2023-07-19T03:34:11,526 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:34:11,530 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=111
2023-07-19T03:34:11,531 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:34:11,541 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,541 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,541 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - [PID]95
2023-07-19T03:34:11,541 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,542 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,542 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,542 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,542 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:34:11,542 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2023-07-19T03:34:11,544 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651544
2023-07-19T03:34:11,544 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651544
2023-07-19T03:34:11,545 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,545 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2023-07-19T03:34:11,546 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - [PID]111
2023-07-19T03:34:11,546 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,547 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,547 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,547 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,547 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:34:11,547 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2023-07-19T03:34:11,554 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651554
2023-07-19T03:34:11,554 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2023-07-19T03:34:11,554 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651554
2023-07-19T03:34:11,557 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=91
2023-07-19T03:34:11,559 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:34:11,577 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,580 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,592 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,593 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - [PID]91
2023-07-19T03:34:11,593 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,593 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,593 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,593 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,594 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:34:11,594 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2023-07-19T03:34:11,608 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2023-07-19T03:34:11,608 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651608
2023-07-19T03:34:11,608 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651608
2023-07-19T03:34:11,636 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,643 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=107
2023-07-19T03:34:11,644 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:34:11,645 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,647 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,655 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=102
2023-07-19T03:34:11,656 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:34:11,658 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,658 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - [PID]107
2023-07-19T03:34:11,658 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,658 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,658 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,658 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,659 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:34:11,659 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2023-07-19T03:34:11,661 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2023-07-19T03:34:11,661 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651661
2023-07-19T03:34:11,661 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651661
2023-07-19T03:34:11,670 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,670 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,670 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - [PID]102
2023-07-19T03:34:11,671 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,671 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,671 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,671 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,671 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:34:11,671 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2023-07-19T03:34:11,680 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651680
2023-07-19T03:34:11,680 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2023-07-19T03:34:11,680 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651680
2023-07-19T03:34:11,683 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,684 [INFO ] W-9006-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,704 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,705 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,710 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=110
2023-07-19T03:34:11,711 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:34:11,721 [INFO ] W-9001-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,724 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,724 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - [PID]110
2023-07-19T03:34:11,725 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,725 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,725 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=108
2023-07-19T03:34:11,725 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,725 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,726 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:34:11,726 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2023-07-19T03:34:11,726 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:34:11,728 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2023-07-19T03:34:11,729 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651729
2023-07-19T03:34:11,729 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651729
2023-07-19T03:34:11,745 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,746 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - [PID]108
2023-07-19T03:34:11,746 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,747 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,747 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,747 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,747 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:34:11,747 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2023-07-19T03:34:11,754 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,754 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=101
2023-07-19T03:34:11,757 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:34:11,761 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651761
2023-07-19T03:34:11,761 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651761
2023-07-19T03:34:11,761 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2023-07-19T03:34:11,771 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,773 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - [PID]101
2023-07-19T03:34:11,774 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,774 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,774 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,778 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:34:11,777 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,778 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2023-07-19T03:34:11,798 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,799 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651799
2023-07-19T03:34:11,799 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651799
2023-07-19T03:34:11,805 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2023-07-19T03:34:11,806 [INFO ] W-9003-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,824 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=104
2023-07-19T03:34:11,825 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:34:11,834 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,841 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:11,842 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - [PID]104
2023-07-19T03:34:11,842 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:11,842 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,842 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:11,842 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:11,842 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:34:11,842 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2023-07-19T03:34:11,844 [INFO ] W-9012-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,844 [INFO ] W-9004-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,845 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651845
2023-07-19T03:34:11,845 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737651845
2023-07-19T03:34:11,845 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2023-07-19T03:34:11,848 [INFO ] W-9002-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,875 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:11,924 [INFO ] W-9014-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:11,984 [INFO ] W-9009-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:12,009 [INFO ] W-9007-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:12,011 [INFO ] W-9013-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:12,046 [INFO ] W-9008-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:12,083 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=103
2023-07-19T03:34:12,084 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:34:12,104 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-07-19T03:34:12,105 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - [PID]103
2023-07-19T03:34:12,105 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Torch worker started.
2023-07-19T03:34:12,105 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Python runtime: 3.9.17
2023-07-19T03:34:12,106 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,106 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,106 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,106 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,107 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T03:34:12,106 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,106 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,107 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T03:34:12,107 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 645
2023-07-19T03:34:12,107 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 645
2023-07-19T03:34:12,107 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,107 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,107 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,107 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,107 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T03:34:12,108 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3283.0|#WorkerName:W-9015-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,107 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 632
2023-07-19T03:34:12,108 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,108 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,109 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:12,109 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change null -> WORKER_STARTED
2023-07-19T03:34:12,109 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:67.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,107 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3294.0|#WorkerName:W-9000-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,109 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3289.0|#WorkerName:W-9011-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,110 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:95.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,111 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:62.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,112 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:34:12,112 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2023-07-19T03:34:12,115 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2023-07-19T03:34:12,127 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737652127
2023-07-19T03:34:12,127 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689737652127
2023-07-19T03:34:12,140 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,140 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,142 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 599
2023-07-19T03:34:12,142 [INFO ] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 599
2023-07-19T03:34:12,142 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,142 [DEBUG] W-9006-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,144 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,144 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,144 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 595
2023-07-19T03:34:12,144 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 595
2023-07-19T03:34:12,144 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,144 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,144 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3327.0|#WorkerName:W-9006-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,145 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3325.0|#WorkerName:W-9010-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,146 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:33.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,147 [INFO ] W-9006-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:49.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,157 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-07-19T03:34:12,203 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,203 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,204 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 683
2023-07-19T03:34:12,204 [INFO ] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 683
2023-07-19T03:34:12,204 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,204 [DEBUG] W-9001-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,205 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3390.0|#WorkerName:W-9001-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,206 [INFO ] W-9001-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:63.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,259 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,259 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,259 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 558
2023-07-19T03:34:12,259 [INFO ] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 558
2023-07-19T03:34:12,260 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,260 [DEBUG] W-9002-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,260 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3445.0|#WorkerName:W-9002-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,260 [INFO ] W-9002-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:41.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,275 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,275 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,275 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 630
2023-07-19T03:34:12,275 [INFO ] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 630
2023-07-19T03:34:12,276 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,276 [DEBUG] W-9004-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,276 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3461.0|#WorkerName:W-9004-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,276 [INFO ] W-9004-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:38.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,290 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,290 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,290 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 710
2023-07-19T03:34:12,290 [INFO ] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 710
2023-07-19T03:34:12,290 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,290 [DEBUG] W-9012-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,290 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3469.0|#WorkerName:W-9012-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,291 [INFO ] W-9012-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:27.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,331 [INFO ] W-9005-helmet_detection_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-07-19T03:34:12,335 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,335 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,335 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 576
2023-07-19T03:34:12,335 [INFO ] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 576
2023-07-19T03:34:12,336 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,336 [DEBUG] W-9014-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,336 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3513.0|#WorkerName:W-9014-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,337 [INFO ] W-9014-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:32.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,365 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,365 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,365 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 791
2023-07-19T03:34:12,365 [INFO ] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 791
2023-07-19T03:34:12,365 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,365 [DEBUG] W-9003-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,365 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3550.0|#WorkerName:W-9003-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,366 [INFO ] W-9003-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:31.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,392 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,392 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,393 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 595
2023-07-19T03:34:12,393 [INFO ] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 595
2023-07-19T03:34:12,393 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,393 [DEBUG] W-9007-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,394 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3578.0|#WorkerName:W-9007-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,395 [INFO ] W-9007-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:38.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,424 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,424 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,425 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 591
2023-07-19T03:34:12,425 [INFO ] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 591
2023-07-19T03:34:12,426 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,426 [DEBUG] W-9013-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,427 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3605.0|#WorkerName:W-9013-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,428 [INFO ] W-9013-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:38.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,440 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,440 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,440 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 547
2023-07-19T03:34:12,440 [INFO ] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 547
2023-07-19T03:34:12,440 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,440 [DEBUG] W-9008-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,441 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3625.0|#WorkerName:W-9008-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,443 [INFO ] W-9008-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:50.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,460 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,460 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,461 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 756
2023-07-19T03:34:12,461 [INFO ] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 756
2023-07-19T03:34:12,461 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,461 [DEBUG] W-9009-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,462 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3644.0|#WorkerName:W-9009-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,463 [INFO ] W-9009-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:27.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,705 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,705 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:34:12,705 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 548
2023-07-19T03:34:12,705 [INFO ] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 548
2023-07-19T03:34:12,706 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,706 [DEBUG] W-9005-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-07-19T03:34:12,706 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3891.0|#WorkerName:W-9005-helmet_detection_1.0,Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:34:12,707 [INFO ] W-9005-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:32.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737652
2023-07-19T03:35:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18425750732422|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06908416748047|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26272.21875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5415.65234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737710
2023-07-19T03:35:50,650 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689737750
2023-07-19T03:35:50,652 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689737750652
2023-07-19T03:35:50,652 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689737750652
2023-07-19T03:35:50,656 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689737750
2023-07-19T03:35:50,679 [WARN ] W-9015-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T03:35:50,680 [WARN ] W-9015-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T03:35:50,951 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:295.8|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737750,b0bd9f1b-9ef0-46fc-8e2f-259b26ee7179, pattern=[METRICS]
2023-07-19T03:35:50,951 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:295.8|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737750,b0bd9f1b-9ef0-46fc-8e2f-259b26ee7179, pattern=[METRICS]
2023-07-19T03:35:50,952 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:295.8|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:b0bd9f1b-9ef0-46fc-8e2f-259b26ee7179,timestamp:1689737750
2023-07-19T03:35:50,952 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:296.44|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737750,b0bd9f1b-9ef0-46fc-8e2f-259b26ee7179, pattern=[METRICS]
2023-07-19T03:35:50,952 [INFO ] W-9015-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:296.44|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737750,b0bd9f1b-9ef0-46fc-8e2f-259b26ee7179, pattern=[METRICS]
2023-07-19T03:35:50,952 [INFO ] W-9015-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:296.44|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:b0bd9f1b-9ef0-46fc-8e2f-259b26ee7179,timestamp:1689737750
2023-07-19T03:35:50,955 [INFO ] W-9015-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51538 "POST /predictions/helmet_detection HTTP/1.1" 200 308
2023-07-19T03:35:50,956 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737750
2023-07-19T03:35:50,956 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:301541.638|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689737750
2023-07-19T03:35:50,956 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:363.138|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689737750
2023-07-19T03:35:50,956 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 363138, Backend time ns: 303982244
2023-07-19T03:35:50,956 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 363138, Backend time ns: 303982244
2023-07-19T03:35:50,956 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737750
2023-07-19T03:35:50,957 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:35:50,957 [DEBUG] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:35:50,957 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 297
2023-07-19T03:35:50,957 [INFO ] W-9015-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 297
2023-07-19T03:35:50,957 [INFO ] W-9015-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737750
2023-07-19T03:36:10,155 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:36:10,156 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184200286865234|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:36:10,157 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06914138793945|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:36:10,158 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:36:10,158 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26138.6484375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:36:10,159 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5549.23046875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:36:10,159 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737770
2023-07-19T03:37:10,126 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:37:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184200286865234|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:37:10,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06914138793945|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:37:10,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:37:10,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26136.7265625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:37:10,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5551.23828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:37:10,130 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737830
2023-07-19T03:38:10,126 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:38:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18419647216797|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:38:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06914520263672|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:38:10,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:38:10,128 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26136.15234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:38:10,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5551.8203125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:38:10,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737890
2023-07-19T03:39:10,137 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18419647216797|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06914520263672|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26136.73828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5551.234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:18.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737950
2023-07-19T03:39:34,244 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689737974
2023-07-19T03:39:34,245 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689737974245
2023-07-19T03:39:34,245 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689737974245
2023-07-19T03:39:34,248 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689737974
2023-07-19T03:39:34,263 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T03:39:34,264 [WARN ] W-9000-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T03:39:34,532 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:282.93|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737974,b9616107-f5d9-4d42-b785-ef540b34182b, pattern=[METRICS]
2023-07-19T03:39:34,532 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:282.93|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737974,b9616107-f5d9-4d42-b785-ef540b34182b, pattern=[METRICS]
2023-07-19T03:39:34,532 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:282.93|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:b9616107-f5d9-4d42-b785-ef540b34182b,timestamp:1689737974
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:283.56|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737974,b9616107-f5d9-4d42-b785-ef540b34182b, pattern=[METRICS]
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:283.56|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689737974,b9616107-f5d9-4d42-b785-ef540b34182b, pattern=[METRICS]
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51542 "POST /predictions/helmet_detection HTTP/1.1" 200 289
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:283.56|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:b9616107-f5d9-4d42-b785-ef540b34182b,timestamp:1689737974
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737974
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:287372.28|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689737974
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:260.063|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689737974
2023-07-19T03:39:34,533 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 260063, Backend time ns: 287954665
2023-07-19T03:39:34,533 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 260063, Backend time ns: 287954665
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737974
2023-07-19T03:39:34,533 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:39:34,533 [DEBUG] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 285
2023-07-19T03:39:34,533 [INFO ] W-9000-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 285
2023-07-19T03:39:34,534 [INFO ] W-9000-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689737974
2023-07-19T03:40:10,149 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:10,152 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18418502807617|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:10,155 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069156646728516|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:10,156 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:10,157 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26022.953125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:10,157 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5665.01953125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:10,158 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738010
2023-07-19T03:40:38,210 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689738038
2023-07-19T03:40:38,212 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689738038211
2023-07-19T03:40:38,212 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689738038211
2023-07-19T03:40:38,215 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689738038
2023-07-19T03:40:38,238 [WARN ] W-9011-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T03:40:38,240 [WARN ] W-9011-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T03:40:38,522 [INFO ] W-9011-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:306.35|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738038,28669402-10a5-4d54-a4e0-4b2908b35d0e, pattern=[METRICS]
2023-07-19T03:40:38,522 [INFO ] W-9011-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:306.35|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738038,28669402-10a5-4d54-a4e0-4b2908b35d0e, pattern=[METRICS]
2023-07-19T03:40:38,522 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:306.35|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:28669402-10a5-4d54-a4e0-4b2908b35d0e,timestamp:1689738038
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:306.99|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738038,28669402-10a5-4d54-a4e0-4b2908b35d0e, pattern=[METRICS]
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:306.99|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738038,28669402-10a5-4d54-a4e0-4b2908b35d0e, pattern=[METRICS]
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:306.99|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:28669402-10a5-4d54-a4e0-4b2908b35d0e,timestamp:1689738038
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51552 "POST /predictions/helmet_detection HTTP/1.1" 200 313
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738038
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:311703.12|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689738038
2023-07-19T03:40:38,523 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:269.457|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689738038
2023-07-19T03:40:38,524 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 269457, Backend time ns: 312272019
2023-07-19T03:40:38,524 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 269457, Backend time ns: 312272019
2023-07-19T03:40:38,524 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738038
2023-07-19T03:40:38,524 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:40:38,524 [DEBUG] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:40:38,524 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 310
2023-07-19T03:40:38,524 [INFO ] W-9011-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 310
2023-07-19T03:40:38,524 [INFO ] W-9011-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738038
2023-07-19T03:41:10,135 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18416213989258|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06917953491211|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25933.3828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5754.58984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.2|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738070
2023-07-19T03:41:32,284 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689738092
2023-07-19T03:41:32,285 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689738092285
2023-07-19T03:41:32,285 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689738092285
2023-07-19T03:41:32,289 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_LOG - Backend received inference at: 1689738092
2023-07-19T03:41:32,308 [WARN ] W-9010-helmet_detection_1.0-stderr MODEL_LOG - /home/venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
2023-07-19T03:41:32,309 [WARN ] W-9010-helmet_detection_1.0-stderr MODEL_LOG -   warnings.warn(
2023-07-19T03:41:32,592 [INFO ] W-9010-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:301.88|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738092,8fdd4c77-a443-4229-8ab4-0d55435a340b, pattern=[METRICS]
2023-07-19T03:41:32,592 [INFO ] W-9010-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:301.88|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738092,8fdd4c77-a443-4229-8ab4-0d55435a340b, pattern=[METRICS]
2023-07-19T03:41:32,592 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_METRICS - HandlerTime.ms:301.88|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:8fdd4c77-a443-4229-8ab4-0d55435a340b,timestamp:1689738092
2023-07-19T03:41:32,593 [INFO ] W-9010-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:302.78|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738092,8fdd4c77-a443-4229-8ab4-0d55435a340b, pattern=[METRICS]
2023-07-19T03:41:32,593 [INFO ] W-9010-helmet_detection_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:302.78|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,1689738092,8fdd4c77-a443-4229-8ab4-0d55435a340b, pattern=[METRICS]
2023-07-19T03:41:32,593 [INFO ] W-9010-helmet_detection_1.0-stdout MODEL_METRICS - PredictionTime.ms:302.78|#ModelName:helmet_detection,Level:Model|#hostname:28e99f3ae17a,requestID:8fdd4c77-a443-4229-8ab4-0d55435a340b,timestamp:1689738092
2023-07-19T03:41:32,594 [INFO ] W-9010-helmet_detection_1.0 ACCESS_LOG - /172.17.0.1:51556 "POST /predictions/helmet_detection HTTP/1.1" 200 310
2023-07-19T03:41:32,594 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738092
2023-07-19T03:41:32,595 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:308782.825|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689738092
2023-07-19T03:41:32,595 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:537.698|#model_name:helmet_detection,model_version:default|#hostname:28e99f3ae17a,timestamp:1689738092
2023-07-19T03:41:32,595 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 537698, Backend time ns: 309486491
2023-07-19T03:41:32,595 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 537698, Backend time ns: 309486491
2023-07-19T03:41:32,595 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738092
2023-07-19T03:41:32,595 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:41:32,595 [DEBUG] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-07-19T03:41:32,595 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 306
2023-07-19T03:41:32,595 [INFO ] W-9010-helmet_detection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 306
2023-07-19T03:41:32,596 [INFO ] W-9010-helmet_detection_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738092
2023-07-19T03:42:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:42:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18415832519531|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:42:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069183349609375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:42:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:42:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.9453125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:42:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.02734375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:42:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738130
2023-07-19T03:43:10,128 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:43:10,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18415451049805|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:43:10,129 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06918716430664|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:43:10,129 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:43:10,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.91015625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:43:10,130 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.0625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:43:10,130 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738190
2023-07-19T03:44:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:44:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18415451049805|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:44:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06918716430664|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:44:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:44:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.98828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:44:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:44:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738250
2023-07-19T03:45:10,124 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:45:10,124 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18415451049805|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:45:10,125 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06918716430664|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:45:10,125 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:45:10,125 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.359375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:45:10,126 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.61328125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:45:10,126 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738310
2023-07-19T03:46:10,135 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:46:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18415451049805|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:46:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06918716430664|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:46:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:46:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.00390625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:46:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.96875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:46:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738370
2023-07-19T03:47:10,130 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:47:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184146881103516|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:47:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06919479370117|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:47:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:47:10,132 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25815.609375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:47:10,132 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5872.36328125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:47:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738430
2023-07-19T03:48:10,139 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:48:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184146881103516|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:48:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06919479370117|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:48:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:48:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25821.046875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:48:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5866.92578125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:48:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738490
2023-07-19T03:49:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:49:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184146881103516|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:49:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06919479370117|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:49:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:49:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.640625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:49:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5864.3359375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:49:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738550
2023-07-19T03:50:10,135 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:50:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184146881103516|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:50:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06919479370117|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:50:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:50:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.84375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:50:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5864.1328125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:50:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738610
2023-07-19T03:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:51:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18414306640625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:51:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06919860839844|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:51:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:51:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.47265625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:51:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5864.50390625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:51:10,143 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738670
2023-07-19T03:52:10,135 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:52:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184139251708984|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:52:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692024230957|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:52:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:52:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.8984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:52:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.078125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:52:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738730
2023-07-19T03:53:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:53:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184139251708984|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:53:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692024230957|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:53:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:53:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.9921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:53:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5863.984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:53:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738790
2023-07-19T03:54:10,144 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:54:10,146 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18413543701172|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:54:10,147 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06920623779297|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:54:10,149 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:54:10,150 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25825.5078125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:54:10,151 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5862.46875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:54:10,152 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738850
2023-07-19T03:55:10,138 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:55:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18413543701172|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:55:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06920623779297|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:55:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:55:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25825.07421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:55:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5862.90234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:55:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738910
2023-07-19T03:56:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:56:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18413543701172|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:56:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06920623779297|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:56:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:56:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25826.3828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:56:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5861.59375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:56:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689738970
2023-07-19T03:57:10,135 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:57:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18413162231445|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:57:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069210052490234|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:57:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:57:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25826.578125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:57:10,144 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5861.3984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:57:10,145 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739030
2023-07-19T03:58:10,145 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:58:10,147 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18412780761719|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:58:10,148 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692138671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:58:10,150 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:58:10,152 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25824.1875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:58:10,152 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5863.7890625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:58:10,153 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739090
2023-07-19T03:59:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T03:59:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18412780761719|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T03:59:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692138671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T03:59:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T03:59:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.5390625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T03:59:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5864.4375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T03:59:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739150
2023-07-19T04:00:10,130 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:00:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18412780761719|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:00:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692138671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:00:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:00:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.65234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:00:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5864.32421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:00:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739210
2023-07-19T04:01:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:01:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18412780761719|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:01:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692138671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:01:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:01:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25823.19921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:01:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5864.77734375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:01:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739270
2023-07-19T04:02:10,135 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:02:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184120178222656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:02:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922149658203|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:02:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:02:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.22265625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:02:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.75390625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:02:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739330
2023-07-19T04:03:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:03:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184120178222656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:03:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922149658203|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:03:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:03:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.2109375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:03:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.765625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:03:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739390
2023-07-19T04:04:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:04:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184120178222656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:04:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922149658203|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:04:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:04:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.10546875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:04:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.87109375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:04:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739450
2023-07-19T04:05:10,137 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:05:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184120178222656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:05:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922149658203|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:05:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:05:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.0390625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:05:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.9375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:05:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739510
2023-07-19T04:06:10,137 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:06:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18411636352539|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:06:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0692253112793|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:06:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:06:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.765625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:06:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.2109375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:06:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739570
2023-07-19T04:07:10,139 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:07:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184112548828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:07:10,142 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922912597656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:07:10,143 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:07:10,144 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.31640625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:07:10,144 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.66015625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:07:10,145 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739630
2023-07-19T04:08:10,138 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:08:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184112548828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:08:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922912597656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:08:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:08:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.3984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:08:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.578125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:08:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739690
2023-07-19T04:09:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:09:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184112548828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:09:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06922912597656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:09:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:09:10,132 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25821.80859375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:09:10,132 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5866.16796875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:09:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739750
2023-07-19T04:10:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:10:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18410873413086|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:10:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06923294067383|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:10:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:10:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:10:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.6015625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:10:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739810
2023-07-19T04:11:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:11:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18410873413086|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:11:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06923294067383|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:11:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:11:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.82421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:11:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.15234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:11:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739870
2023-07-19T04:12:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:12:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184104919433594|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:12:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069236755371094|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:12:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:12:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.4296875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:12:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.546875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:12:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739930
2023-07-19T04:13:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:13:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184104919433594|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:13:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069236755371094|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:13:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:13:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.95703125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:13:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.01953125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:13:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689739990
2023-07-19T04:14:10,136 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:14:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18410110473633|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:14:10,136 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06924057006836|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:14:10,137 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:14:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.35546875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:14:10,137 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.62109375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:14:10,138 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740050
2023-07-19T04:15:10,150 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:15:10,151 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18410110473633|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:15:10,151 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06924057006836|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:15:10,151 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:15:10,151 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.8046875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:15:10,151 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.171875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:15:10,151 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740110
2023-07-19T04:16:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:16:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18410110473633|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:16:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06924057006836|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:16:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:16:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.3671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:16:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.609375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:16:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740170
2023-07-19T04:17:10,138 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:17:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18409729003906|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:17:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069244384765625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:17:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:17:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.36328125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:17:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.61328125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:17:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740230
2023-07-19T04:18:10,138 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:18:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.1840934753418|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:18:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06924819946289|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:18:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:18:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.484375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:18:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.4921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:18:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740290
2023-07-19T04:19:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:19:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.1840934753418|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:19:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06924819946289|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:19:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:19:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.3046875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:19:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:19:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740350
2023-07-19T04:20:10,125 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:20:10,126 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.1840934753418|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:20:10,126 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06924819946289|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:20:10,126 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:20:10,127 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.8046875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:20:10,127 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.171875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:20:10,127 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740410
2023-07-19T04:21:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:21:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18408966064453|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:21:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069252014160156|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:21:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:21:10,132 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.7421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:21:10,132 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:21:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740470
2023-07-19T04:22:10,125 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:22:10,127 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:35.184085845947266|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:22:10,127 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:58.06925582885742|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:22:10,127 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:22:10,127 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:25820.65234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:22:10,127 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:5867.32421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:22:10,127 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740530
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:35.184085845947266|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:58.06925582885742|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:25821.06640625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:5866.91015625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:23:10,133 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740590
2023-07-19T04:24:10,128 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:24:10,128 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:35.184085845947266|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:24:10,129 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:58.06925582885742|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:24:10,129 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:24:10,129 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:25821.48828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:24:10,130 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:5866.48828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:24:10,130 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740650
2023-07-19T04:25:10,127 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:25:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18408203125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:25:10,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06925964355469|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:25:10,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:25:10,128 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25822.0859375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:25:10,128 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5865.890625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:25:10,128 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740710
2023-07-19T04:26:10,144 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:26:10,144 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18408203125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:26:10,144 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06925964355469|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:26:10,145 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:26:10,145 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25821.828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:26:10,145 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5866.1484375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:26:10,145 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740770
2023-07-19T04:27:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:27:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184078216552734|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:27:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06926345825195|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:27:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:27:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25821.13671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:27:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5866.83984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:27:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740830
2023-07-19T04:28:10,139 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:28:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184078216552734|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:28:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06926345825195|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:28:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:28:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.69921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:28:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.27734375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:28:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740890
2023-07-19T04:29:10,138 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:29:10,138 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18407440185547|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:29:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06926727294922|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:29:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:29:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.40625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:29:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.5703125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:29:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689740950
2023-07-19T04:30:10,125 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:30:10,125 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18407440185547|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:30:10,126 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06926727294922|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:30:10,126 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:30:10,126 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25820.10546875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:30:10,126 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5867.87109375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:30:10,126 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741010
2023-07-19T04:31:10,139 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:31:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18407440185547|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:31:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06926727294922|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:31:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:31:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25819.04296875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:31:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5868.93359375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:31:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741070
2023-07-19T04:32:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:32:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.1840705871582|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:32:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.069271087646484|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:32:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:32:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25817.6875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:32:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5870.2890625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:32:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741130
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18406677246094|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06927490234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.69921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.27734375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:33:10,131 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741190
2023-07-19T04:34:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:34:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18406677246094|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:34:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06927490234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:34:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:34:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25817.21484375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:34:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5870.76171875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:34:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741250
2023-07-19T04:35:10,127 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:35:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18406677246094|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:35:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06927490234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:35:10,127 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:35:10,127 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.8046875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:35:10,127 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.171875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:35:10,128 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741310
2023-07-19T04:36:10,139 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:36:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18406677246094|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:36:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06927490234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:36:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:36:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25817.5234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:36:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5870.453125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:36:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741370
2023-07-19T04:37:10,145 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:37:10,145 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184059143066406|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:37:10,145 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06928253173828|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:37:10,146 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:37:10,146 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25816.7265625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:37:10,146 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5871.25|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:37:10,146 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741430
2023-07-19T04:38:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:38:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184059143066406|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:38:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06928253173828|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:38:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:38:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25817.76171875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:38:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5870.21484375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:38:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741490
2023-07-19T04:39:10,140 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:39:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184059143066406|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:39:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06928253173828|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:39:10,141 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:39:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.0625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:39:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.9140625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:39:10,142 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741550
2023-07-19T04:40:10,139 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:40:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184059143066406|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:40:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06928253173828|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:40:10,140 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:40:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.01953125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:40:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.95703125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:40:10,140 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741610
2023-07-19T04:41:10,129 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:41:10,130 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18405532836914|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:41:10,130 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06928634643555|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:41:10,130 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:41:10,131 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25818.15625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:41:10,131 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5869.8203125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:41:10,131 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741670
2023-07-19T04:42:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:42:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184051513671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:42:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06929016113281|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:42:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:42:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25816.421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:42:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5871.5546875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:42:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741730
2023-07-19T04:43:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:20.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:43:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184051513671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:43:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06929016113281|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:43:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:43:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25815.4765625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:43:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5872.5|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:43:10,136 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741790
2023-07-19T04:44:10,146 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:44:10,147 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.184051513671875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:44:10,148 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06929016113281|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:44:10,151 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:44:10,152 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25815.53125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:44:10,153 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5872.4453125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:44:10,154 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741850
2023-07-19T04:45:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:45:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18404769897461|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:45:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06929397583008|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:45:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:45:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25814.796875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:45:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5873.1796875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:45:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741910
2023-07-19T04:46:10,134 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:46:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18404769897461|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:46:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06929397583008|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:46:10,135 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:46:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25815.06640625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:46:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5872.91015625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:46:10,141 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689741970
2023-07-19T04:47:10,138 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:47:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18400573730469|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:47:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.0693359375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:47:10,139 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:47:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25730.14453125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:47:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5957.828125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:47:10,139 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.9|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742030
2023-07-19T04:48:10,131 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:48:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18397903442383|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:48:10,132 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06936264038086|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:48:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:48:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25733.140625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:48:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5954.83203125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:48:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.9|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742090
2023-07-19T04:49:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:49:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18397903442383|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:49:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06936264038086|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:49:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:49:10,133 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25732.0234375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:49:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5955.94921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:49:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.9|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742150
2023-07-19T04:50:10,132 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:50:10,133 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18397903442383|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:50:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06936264038086|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:50:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:50:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25731.07421875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:50:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5956.8984375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:50:10,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.9|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742210
2023-07-19T04:51:10,133 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.18397903442383|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.06936264038086|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25731.09375|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5956.87890625|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:51:10,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.9|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742270
2023-07-19T04:52:10,188 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:6.7|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
2023-07-19T04:52:10,188 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:35.136024475097656|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
2023-07-19T04:52:10,188 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:58.11731719970703|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
2023-07-19T04:52:10,188 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:62.3|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
2023-07-19T04:52:10,188 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25805.921875|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
2023-07-19T04:52:10,189 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5882.05078125|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
2023-07-19T04:52:10,189 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:19.6|#Level:Host|#hostname:28e99f3ae17a,timestamp:1689742330
